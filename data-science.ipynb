{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_shape_of_dataframes(**kwargs):\n",
    "    \"\"\"\n",
    "    Print the shape (number of rows and columns) of multiple pandas DataFrame\n",
    "    objects.\n",
    "\n",
    "    Parameters:\n",
    "    -------------\n",
    "    **kwargs: dict\n",
    "        Keyword arguments where the keys are the names of the DataFrame\n",
    "        objects (as string) and the values are the DataFrame objects\n",
    "        themselves.\n",
    "\n",
    "    Notes:\n",
    "    ------------\n",
    "    The functon dynamically handles any number of DataFrame objects passed\n",
    "    as keyword arguments.\n",
    "    Ensure the passed objects are valid pandas DataFrame to avoid unexpected\n",
    "    errors.\n",
    "    \"\"\"\n",
    "    for name, value in kwargs.items():\n",
    "        if hasattr(value, 'shape'):\n",
    "            print(f'DataFrame \\033[94m{name.title()}\\033[0m has {value.shape[0]} rows and {value.shape[1]} columns.')\n",
    "            print('------------------------------------')\n",
    "        else:\n",
    "            raise ValueError(f'The object 033[94m{name.title()}\\033[0m is not a valid DataFrame.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def delete_outliers(data_frame: pd.DataFrame, n: int, features: list) -> list:\n",
    "    \"\"\"\n",
    "    Detect and Identifies outliers in the specified features of a \n",
    "    DataFrame.\n",
    "\n",
    "    This function iterates through a list of numerical features and detects\n",
    "    outliers in each feature based on the IQR method. An outlier is defined\n",
    "    as a value below Q1 - 1.5 * IQR or above Q3 + 1.5 * IQR.\n",
    "    If an index appears as an outlier in more than N features, it is added to the \n",
    "    final list of multiple outliers.\n",
    "\n",
    "    Parameters:\n",
    "    ---------------\n",
    "    data_frame: pd.DataFrame\n",
    "        The DataFrame containing the data to analyze.\n",
    "\n",
    "    n: int\n",
    "        The minimum number of features in which a data point must be an outlier\n",
    "        to be considered a multiple outlier.\n",
    "\n",
    "    features: list\n",
    "        A list of column names (features) to analyze for outliers.\n",
    "        Those should be numerical columns.\n",
    "\n",
    "    Returns:\n",
    "    -------------\n",
    "    list\n",
    "        A list of indices corresponding to data points that are outliers\n",
    "        in more than n features.\n",
    "\n",
    "    Raises:\n",
    "    ------------\n",
    "    TypeError\n",
    "        If data_frame is not a pandas DataFrame, or if features is not a list.\n",
    "\n",
    "    ValueError\n",
    "        If n is negative, or if a feature in the features list is not in\n",
    "        the DataFrame.\n",
    "    \"\"\"\n",
    "    if not isinstance(data_frame, pd.DataFrame):\n",
    "        raise TypeError(\"`data_frame` must be a pandas DataFrame.\")\n",
    "    if not isinstance(features, list):\n",
    "        raise TypeError(\"`features` must be a list of column names.\")\n",
    "    if not isinstance(n, int) or n < 0:\n",
    "        raise ValueError(\"`n` must be a non-negative integer.\")\n",
    "        \n",
    "    outliers = []\n",
    "    for feature in features:\n",
    "        Q1 = np.percentile(data_frame[feature], 25)\n",
    "        Q3 = np.percentile(data_frame[feature], 75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5*IQR\n",
    "        upper = Q3 + 1.5*IQR\n",
    "\n",
    "        outlier_list = data_frame[(data_frame[feature] < lower) | (data_frame[feature] > upper)].index\n",
    "        outliers.extend(outlier_list)\n",
    "    outliers = Counter(outliers)\n",
    "    multiple_outliers = list(key for key, value in outliers.items() if value > n)\n",
    "    return multiple_outliers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import missingno\n",
    "import re\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import and Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Estimate</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Headquarters</th>\n",
       "      <th>Size</th>\n",
       "      <th>Founded</th>\n",
       "      <th>Type of ownership</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Competitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>$137K-$171K (Glassdoor est.)</td>\n",
       "      <td>Description\\n\\nThe Senior Data Scientist is re...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Healthfirst\\n3.1</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1001 to 5000 employees</td>\n",
       "      <td>1993</td>\n",
       "      <td>Nonprofit Organization</td>\n",
       "      <td>Insurance Carriers</td>\n",
       "      <td>Insurance</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>EmblemHealth, UnitedHealth Group, Aetna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>$137K-$171K (Glassdoor est.)</td>\n",
       "      <td>Secure our Nation, Ignite your Future\\n\\nJoin ...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>ManTech\\n4.2</td>\n",
       "      <td>Chantilly, VA</td>\n",
       "      <td>Herndon, VA</td>\n",
       "      <td>5001 to 10000 employees</td>\n",
       "      <td>1968</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>$1 to $2 billion (USD)</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>$137K-$171K (Glassdoor est.)</td>\n",
       "      <td>Overview\\n\\n\\nAnalysis Group is one of the lar...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Analysis Group\\n3.8</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>1001 to 5000 employees</td>\n",
       "      <td>1981</td>\n",
       "      <td>Private Practice / Firm</td>\n",
       "      <td>Consulting</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>$100 to $500 million (USD)</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>$137K-$171K (Glassdoor est.)</td>\n",
       "      <td>JOB DESCRIPTION:\\n\\nDo you have a passion for ...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>INFICON\\n3.5</td>\n",
       "      <td>Newton, MA</td>\n",
       "      <td>Bad Ragaz, Switzerland</td>\n",
       "      <td>501 to 1000 employees</td>\n",
       "      <td>2000</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Electrical &amp; Electronic Manufacturing</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>$100 to $500 million (USD)</td>\n",
       "      <td>MKS Instruments, Pfeiffer Vacuum, Agilent Tech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>$137K-$171K (Glassdoor est.)</td>\n",
       "      <td>Data Scientist\\nAffinity Solutions / Marketing...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>Affinity Solutions\\n2.9</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>51 to 200 employees</td>\n",
       "      <td>1998</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Advertising &amp; Marketing</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>Commerce Signals, Cardlytics, Yodlee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index          Job Title               Salary Estimate  \\\n",
       "0      0  Sr Data Scientist  $137K-$171K (Glassdoor est.)   \n",
       "1      1     Data Scientist  $137K-$171K (Glassdoor est.)   \n",
       "2      2     Data Scientist  $137K-$171K (Glassdoor est.)   \n",
       "3      3     Data Scientist  $137K-$171K (Glassdoor est.)   \n",
       "4      4     Data Scientist  $137K-$171K (Glassdoor est.)   \n",
       "\n",
       "                                     Job Description  Rating  \\\n",
       "0  Description\\n\\nThe Senior Data Scientist is re...     3.1   \n",
       "1  Secure our Nation, Ignite your Future\\n\\nJoin ...     4.2   \n",
       "2  Overview\\n\\n\\nAnalysis Group is one of the lar...     3.8   \n",
       "3  JOB DESCRIPTION:\\n\\nDo you have a passion for ...     3.5   \n",
       "4  Data Scientist\\nAffinity Solutions / Marketing...     2.9   \n",
       "\n",
       "              Company Name       Location            Headquarters  \\\n",
       "0         Healthfirst\\n3.1   New York, NY            New York, NY   \n",
       "1             ManTech\\n4.2  Chantilly, VA             Herndon, VA   \n",
       "2      Analysis Group\\n3.8     Boston, MA              Boston, MA   \n",
       "3             INFICON\\n3.5     Newton, MA  Bad Ragaz, Switzerland   \n",
       "4  Affinity Solutions\\n2.9   New York, NY            New York, NY   \n",
       "\n",
       "                      Size  Founded        Type of ownership  \\\n",
       "0   1001 to 5000 employees     1993   Nonprofit Organization   \n",
       "1  5001 to 10000 employees     1968         Company - Public   \n",
       "2   1001 to 5000 employees     1981  Private Practice / Firm   \n",
       "3    501 to 1000 employees     2000         Company - Public   \n",
       "4      51 to 200 employees     1998        Company - Private   \n",
       "\n",
       "                                Industry             Sector  \\\n",
       "0                     Insurance Carriers          Insurance   \n",
       "1                 Research & Development  Business Services   \n",
       "2                             Consulting  Business Services   \n",
       "3  Electrical & Electronic Manufacturing      Manufacturing   \n",
       "4                Advertising & Marketing  Business Services   \n",
       "\n",
       "                      Revenue  \\\n",
       "0    Unknown / Non-Applicable   \n",
       "1      $1 to $2 billion (USD)   \n",
       "2  $100 to $500 million (USD)   \n",
       "3  $100 to $500 million (USD)   \n",
       "4    Unknown / Non-Applicable   \n",
       "\n",
       "                                         Competitors  \n",
       "0            EmblemHealth, UnitedHealth Group, Aetna  \n",
       "1                                                 -1  \n",
       "2                                                 -1  \n",
       "3  MKS Instruments, Pfeiffer Vacuum, Agilent Tech...  \n",
       "4               Commerce Signals, Cardlytics, Yodlee  "
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Uncleaned_DS_jobs.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Estimate</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Headquarters</th>\n",
       "      <th>Size</th>\n",
       "      <th>Type of ownership</th>\n",
       "      <th>Industry</th>\n",
       "      <th>...</th>\n",
       "      <th>company_age</th>\n",
       "      <th>python</th>\n",
       "      <th>excel</th>\n",
       "      <th>hadoop</th>\n",
       "      <th>spark</th>\n",
       "      <th>aws</th>\n",
       "      <th>tableau</th>\n",
       "      <th>big_data</th>\n",
       "      <th>job_simp</th>\n",
       "      <th>seniority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>137-171</td>\n",
       "      <td>Description\\n\\nThe Senior Data Scientist is re...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Healthfirst</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1001 to 5000 employees</td>\n",
       "      <td>Nonprofit Organization</td>\n",
       "      <td>Insurance Carriers</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>137-171</td>\n",
       "      <td>Secure our Nation, Ignite your Future\\n\\nJoin ...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>ManTech</td>\n",
       "      <td>Chantilly, VA</td>\n",
       "      <td>Herndon, VA</td>\n",
       "      <td>5001 to 10000 employees</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>137-171</td>\n",
       "      <td>Overview\\n\\n\\nAnalysis Group is one of the lar...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Analysis Group</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>1001 to 5000 employees</td>\n",
       "      <td>Private Practice / Firm</td>\n",
       "      <td>Consulting</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>137-171</td>\n",
       "      <td>JOB DESCRIPTION:\\n\\nDo you have a passion for ...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>INFICON</td>\n",
       "      <td>Newton, MA</td>\n",
       "      <td>Bad Ragaz, Switzerland</td>\n",
       "      <td>501 to 1000 employees</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Electrical &amp; Electronic Manufacturing</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>137-171</td>\n",
       "      <td>Data Scientist\\nAffinity Solutions / Marketing...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>Affinity Solutions</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>51 to 200 employees</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Advertising &amp; Marketing</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Job Title Salary Estimate  \\\n",
       "0  Sr Data Scientist        137-171    \n",
       "1     Data Scientist        137-171    \n",
       "2     Data Scientist        137-171    \n",
       "3     Data Scientist        137-171    \n",
       "4     Data Scientist        137-171    \n",
       "\n",
       "                                     Job Description  Rating  \\\n",
       "0  Description\\n\\nThe Senior Data Scientist is re...     3.1   \n",
       "1  Secure our Nation, Ignite your Future\\n\\nJoin ...     4.2   \n",
       "2  Overview\\n\\n\\nAnalysis Group is one of the lar...     3.8   \n",
       "3  JOB DESCRIPTION:\\n\\nDo you have a passion for ...     3.5   \n",
       "4  Data Scientist\\nAffinity Solutions / Marketing...     2.9   \n",
       "\n",
       "         Company Name       Location            Headquarters  \\\n",
       "0         Healthfirst   New York, NY            New York, NY   \n",
       "1             ManTech  Chantilly, VA             Herndon, VA   \n",
       "2      Analysis Group     Boston, MA              Boston, MA   \n",
       "3             INFICON     Newton, MA  Bad Ragaz, Switzerland   \n",
       "4  Affinity Solutions   New York, NY            New York, NY   \n",
       "\n",
       "                      Size        Type of ownership  \\\n",
       "0   1001 to 5000 employees   Nonprofit Organization   \n",
       "1  5001 to 10000 employees         Company - Public   \n",
       "2   1001 to 5000 employees  Private Practice / Firm   \n",
       "3    501 to 1000 employees         Company - Public   \n",
       "4      51 to 200 employees        Company - Private   \n",
       "\n",
       "                                Industry  ... company_age python  excel  \\\n",
       "0                     Insurance Carriers  ...          27      0      0   \n",
       "1                 Research & Development  ...          52      0      0   \n",
       "2                             Consulting  ...          39      1      1   \n",
       "3  Electrical & Electronic Manufacturing  ...          20      1      1   \n",
       "4                Advertising & Marketing  ...          22      1      1   \n",
       "\n",
       "   hadoop  spark aws  tableau  big_data        job_simp  seniority  \n",
       "0       0      0   1        0         0  data scientist     senior  \n",
       "1       1      0   0        0         1  data scientist         na  \n",
       "2       0      0   1        0         0  data scientist         na  \n",
       "3       0      0   1        0         0  data scientist         na  \n",
       "4       0      0   0        0         0  data scientist         na  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned = pd.read_csv('Cleaned_DS_Jobs.csv')\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame \u001b[94mUncleaned_Df\u001b[0m has 672 rows and 15 columns.\n",
      "------------------------------------\n",
      "DataFrame \u001b[94mCleaned_Df\u001b[0m has 660 rows and 27 columns.\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_shape_of_dataframes(uncleaned_df=df, cleaned_df=df_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw dataset (Uncleaned_DS_jobs.csv) was imported and initially contained 672 rows and 15 columns, representing the unprocessed state of the data with potential inconsistencies, missing values, and redundant information. After cleaning, the dataset (Cleaned_DS_Jobs.csv) was reduced to 660 rows and expanded to 27 columns, indicating the removal of invalid or unnecessary records and the addition of new features or transformations during the cleaning process. This transformation resulted in a more structured and reliable dataset, ready for further analysis or modeling. The changes reflect the efforts to improve data quality and usability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Description and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(672, 15)"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 672 entries, 0 to 671\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   index              672 non-null    int64  \n",
      " 1   Job Title          672 non-null    object \n",
      " 2   Salary Estimate    672 non-null    object \n",
      " 3   Job Description    672 non-null    object \n",
      " 4   Rating             672 non-null    float64\n",
      " 5   Company Name       672 non-null    object \n",
      " 6   Location           672 non-null    object \n",
      " 7   Headquarters       672 non-null    object \n",
      " 8   Size               672 non-null    object \n",
      " 9   Founded            672 non-null    int64  \n",
      " 10  Type of ownership  672 non-null    object \n",
      " 11  Industry           672 non-null    object \n",
      " 12  Sector             672 non-null    object \n",
      " 13  Revenue            672 non-null    object \n",
      " 14  Competitors        672 non-null    object \n",
      "dtypes: float64(1), int64(2), object(12)\n",
      "memory usage: 78.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The uncleaned dataset consists of 672 entries and 15 columns, with a mix of numeric and object data types, including job titles, salary estimates, company details, and descriptive fields. All columns have non-null values, suggesting no missing data, but further inspection is needed to identify potential inconsistencies or formatting issues within the fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'Job Title', 'Salary Estimate', 'Job Description', 'Rating',\n",
       "       'Company Name', 'Location', 'Headquarters', 'Size', 'Founded',\n",
       "       'Type of ownership', 'Industry', 'Sector', 'Revenue', 'Competitors'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Index Feature`\n",
    "\n",
    "The index column in the uncleaned dataset contains sequential integer values from 0 to 671, which do not provide meaningful information for analysis. Therefore, it is considered redundant and should be removed before proceeding with data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
       "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
       "       377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
       "       390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
       "       403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
       "       416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
       "       429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
       "       442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
       "       455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
       "       468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n",
       "       481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
       "       494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n",
       "       507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519,\n",
       "       520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532,\n",
       "       533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n",
       "       546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558,\n",
       "       559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571,\n",
       "       572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584,\n",
       "       585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597,\n",
       "       598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610,\n",
       "       611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623,\n",
       "       624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636,\n",
       "       637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649,\n",
       "       650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662,\n",
       "       663, 664, 665, 666, 667, 668, 669, 670, 671], dtype=int64)"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['index'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_df = df.drop(labels='index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Estimate</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Headquarters</th>\n",
       "      <th>Size</th>\n",
       "      <th>Founded</th>\n",
       "      <th>Type of ownership</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Competitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>$137K-$171K (Glassdoor est.)</td>\n",
       "      <td>Description\\n\\nThe Senior Data Scientist is re...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Healthfirst\\n3.1</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1001 to 5000 employees</td>\n",
       "      <td>1993</td>\n",
       "      <td>Nonprofit Organization</td>\n",
       "      <td>Insurance Carriers</td>\n",
       "      <td>Insurance</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>EmblemHealth, UnitedHealth Group, Aetna</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Job Title               Salary Estimate  \\\n",
       "0  Sr Data Scientist  $137K-$171K (Glassdoor est.)   \n",
       "\n",
       "                                     Job Description  Rating  \\\n",
       "0  Description\\n\\nThe Senior Data Scientist is re...     3.1   \n",
       "\n",
       "       Company Name      Location  Headquarters                    Size  \\\n",
       "0  Healthfirst\\n3.1  New York, NY  New York, NY  1001 to 5000 employees   \n",
       "\n",
       "   Founded       Type of ownership            Industry     Sector  \\\n",
       "0     1993  Nonprofit Organization  Insurance Carriers  Insurance   \n",
       "\n",
       "                    Revenue                              Competitors  \n",
       "0  Unknown / Non-Applicable  EmblemHealth, UnitedHealth Group, Aetna  "
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Job Title Feature`\n",
    "\n",
    "The Job Title column contains various job titles related to data science and other technical roles, including variations such as \"Data Scientist,\" \"Data Engineer,\" \"Machine Learning Engineer,\" and more. Given the diversity and specificity of these titles, we have decided to leave this column as is, without applying any transformations. It is important to retain these distinct titles as they represent unique job roles and are crucial for any analysis regarding job market trends, skill requirements, or salary estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sr Data Scientist', 'Data Scientist',\n",
       "       'Data Scientist / Machine Learning Expert',\n",
       "       'Staff Data Scientist - Analytics',\n",
       "       'Data Scientist - Statistics, Early Career', 'Data Modeler',\n",
       "       'Experienced Data Scientist', 'Data Scientist - Contract',\n",
       "       'Data Analyst II', 'Medical Lab Scientist',\n",
       "       'Data Scientist/Machine Learning', 'Human Factors Scientist',\n",
       "       'Business Intelligence Analyst I- Data Insights',\n",
       "       'Data Scientist - Risk', 'Data Scientist-Human Resources',\n",
       "       'Senior Research Statistician- Data Scientist', 'Data Engineer',\n",
       "       'Associate Data Scientist', 'Business Intelligence Analyst',\n",
       "       'Senior Analyst/Data Scientist', 'Data Analyst',\n",
       "       'Machine Learning Engineer', 'Data Analyst I',\n",
       "       'Scientist - Molecular Biology',\n",
       "       'Computational Scientist, Machine Learning',\n",
       "       'Senior Data Scientist', 'Jr. Data Engineer',\n",
       "       'E-Commerce Data Analyst', 'Data Analytics Engineer',\n",
       "       'Product Data Scientist - Ads Data Science',\n",
       "       'Data Scientist - Intermediate', 'Global Data Analyst',\n",
       "       'Data & Machine Learning Scientist',\n",
       "       'Data Scientist - Machine Learning', 'Data Engineer (Remote)',\n",
       "       'Data Scientist, Applied Machine Learning - Bay Area',\n",
       "       'Principal Data Scientist', 'Business Data Analyst',\n",
       "       'Purification Scientist', 'Data Engineer, Enterprise Analytics',\n",
       "       'Data Scientist 3 (718)', 'Real World Science, Data Scientist',\n",
       "       'Data Scientist - Image and Video Analytics',\n",
       "       'Data Science Manager, Payment Acceptance - USA',\n",
       "       'Data Scientist / Applied Mathematician',\n",
       "       'Patient Safety- Associate Data Scientist',\n",
       "       '(Sr.) Data Scientist -', 'Data Scientist, Kinship - NYC/Portland',\n",
       "       'Applied Technology Researcher / Data Scientist',\n",
       "       'Health Data Scientist - Biomedical/Biostats',\n",
       "       'Staff Data Scientist', 'Sr Data Engineer (Sr BI Developer)',\n",
       "       'Lead Data Scientist', 'RFP Data Analyst',\n",
       "       'Data Scientist (TS/SCI)', 'Software Engineer - Data Science',\n",
       "       'Data Analyst/Engineer', 'NGS Scientist', 'Senior Data Engineer',\n",
       "       'Sr. ML/Data Scientist - AI/NLP/Chatbot',\n",
       "       'Data Integration and Modeling Engineer',\n",
       "       'Tableau Data Engineer 20-0117', 'AI Data Scientist',\n",
       "       'Research Scientist Patient Preferences (Remote)',\n",
       "       'Scientist - Biomarker and Flow Cytometry', 'Analytics Manager',\n",
       "       'Staff Scientist- Upstream PD',\n",
       "       'Sr Scientist - Extractables & Leachables',\n",
       "       'ELISA RESEARCH SCIENTIST (CV-15)', 'Say Business Data Analyst',\n",
       "       'Geospatial Data Scientist', 'Computational Scientist',\n",
       "       'Senior Data Analyst', 'Sr Data Analyst',\n",
       "       'Machine Learning Scientist - Bay Area, CA',\n",
       "       'Senior Data Scientist - Algorithms',\n",
       "       'Senior Data & Machine Learning Scientist',\n",
       "       'Research Scientist - Patient-Centered Research (Remote)',\n",
       "       'Jr. Business Data Analyst (position added 6/12/2020)',\n",
       "       'Sr. Data Scientist II',\n",
       "       'Production Engineer - Statistics/Data Analysis',\n",
       "       'Statistical Scientist', 'Computational Behavioral Scientist',\n",
       "       'Principal Data Scientist - Machine Learning',\n",
       "       'Principal Machine Learning Scientist',\n",
       "       'Senior Data Scientist - R&D Oncology',\n",
       "       'Health Plan Data Analyst, Sr',\n",
       "       'Principal Scientist/Associate Director, Quality Control and Analytical Technologies',\n",
       "       'Analytics - Business Assurance Data Analyst',\n",
       "       'Senior Data Scientist – Image Analytics, Novartis AI Innovation Lab',\n",
       "       'Data Science Instructor', 'Senior Business Intelligence Analyst',\n",
       "       'In-Line Inspection Data Analyst',\n",
       "       'Data Scientist - TS/SCI FSP or CI Required',\n",
       "       'Data Scientist - TS/SCI Required',\n",
       "       'Data Science Software Engineer',\n",
       "       'ENGINEER - COMPUTER SCIENTIST - RESEARCH COMPUTER SCIENTIST - SIGNAL PROCESSING - SAN ANTONIO OR',\n",
       "       'AI Ops Data Scientist', 'Intelligence Data Analyst, Senior',\n",
       "       'Analytics Manager - Data Mart',\n",
       "       'Data Modeler (Analytical Systems)',\n",
       "       'Senior Machine Learning Scientist - Bay Area, CA',\n",
       "       'Report Writer-Data Analyst', 'Staff Data Scientist - Pricing',\n",
       "       'Equity Data Insights Analyst - Quantitative Analyst',\n",
       "       'Operations Data Analyst', 'Software Data Engineer',\n",
       "       'Real World Evidence (RWE) Scientist', 'Computer Scientist 1',\n",
       "       'Environmental Data Science', 'Staff BI and Data Engineer',\n",
       "       'Data Scientist - Statistics, Mid-Career',\n",
       "       'Director of Data Science',\n",
       "       'Data Engineer, Digital & Comp Pathology',\n",
       "       'Manager / Lead, Data Science & Analytics',\n",
       "       'Diversity and Inclusion Data Analyst',\n",
       "       'Data Scientist Machine Learning', 'Chief Scientist',\n",
       "       'Development Scientist, Voltaren',\n",
       "       'Principal Data & Analytics Platform Engineer',\n",
       "       'Machine Learning Engineer/Scientist',\n",
       "       'Data Analyst - Unilever Prestige', 'VP, Data Science',\n",
       "       'Data Engineer - Kafka', 'Decision Scientist',\n",
       "       'Data Science All Star Program - Data Engineer Track',\n",
       "       'Scientist - Machine Learning', 'Sr. Data Scientist',\n",
       "       'Applied AI Scientist / Engineer',\n",
       "       'Data Engineer (Analytics, SQL, Python, AWS)',\n",
       "       'Senior Data Analyst - Finance & Platform Analytics',\n",
       "       'Market Research Data Scientist',\n",
       "       'IT Partner Digital Health Technology and Data Science',\n",
       "       'Software Engineer (Data Scientist, C,C++,Linux,Unix) - SISW - MG',\n",
       "       'Senior Clinical Data Scientist Programmer',\n",
       "       'Computer Vision / Deep Learning Scientist',\n",
       "       'Data Solutions Engineer - Data Modeler',\n",
       "       'Data Scientist (TS/SCI w/ Poly)',\n",
       "       'Weapons and Sensors Engineer/Scientist',\n",
       "       'Applied Computer Scientist', 'Cloud Data Engineer (Azure)',\n",
       "       'Lead Certified Clinical Laboratory Scientist - Saturday - Tuesday, 8:00pm - 6:30am shift',\n",
       "       'Sr. Data Analyst',\n",
       "       'Senior Scientist - Toxicologist - Product Integrity (Stewardship)',\n",
       "       'Senior Machine Learning Engineer',\n",
       "       'Data Scientist- Industrial Discrete Sector Industry',\n",
       "       'Senior Principal Data Scientist (Python/R)',\n",
       "       'Data Scientist(s)/Machine Learning Engineer',\n",
       "       'Scientist / Group Lead, Cancer Biology',\n",
       "       'Manager, Field Application Scientist, Southeast',\n",
       "       'COMPUTER SCIENTIST - ENGINEER - RESEARCH COMPUTER SCIENTIST - SIGNAL PROCESSING',\n",
       "       'Machine Learning Scientist / Engineer', 'Data Science Analyst',\n",
       "       'COMPUTER SCIENTIST - ENGINEER - RESEARCH COMPUTER SCIENTIST - TRANSPORTATION TECHNOLOGY',\n",
       "       'Software Engineer - Machine Learning & Data Science (Applied Intelligence Services Team)',\n",
       "       'Clinical Data Analyst', 'Data Scientist Technical Specialist',\n",
       "       'Data Science Manager', 'Big Data Engineer', 'Data Architect',\n",
       "       'Aviation AI/ML Data Scientist', 'Machine Learning Engineer, Sr.',\n",
       "       'Information Systems Engineering Specialist (Engineering Scientist)',\n",
       "       'Scientist/Research Associate-Metabolic Engineering',\n",
       "       'Vice President, Biometrics and Clinical Data Management',\n",
       "       'Enterprise Data Analyst (Enterprise Portfolio Management Office)',\n",
       "       'Lead Data Scientist – Network Analysis and Control',\n",
       "       'Sr. Research Associate/ Scientist, NGS prep & Molecular Genomics',\n",
       "       'Developer III - Data Science',\n",
       "       'Hydrogen/Tritium Materials Scientist (Experienced)',\n",
       "       'Data Scientist/Data Analytics Practitioner',\n",
       "       'AI/ML - Machine Learning Scientist, Siri Understanding'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df['Job Title'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Salary Estimate Feature`\n",
    "\n",
    "The Salary Estimate column originally contained salary ranges in a string format, including values such as $137K-$171K (Glassdoor est.) and $75K-$131K (Glassdoor est.). To standardize the data and make it more useful for analysis, we cleaned this column by extracting the salary range and removing the text and currency symbols.\n",
    "\n",
    "We used a regular expression to capture the numeric values within the salary range, converting them into a simplified format (e.g., 137-171 for $137K-$171K). This cleaned format provides a consistent range of values for each entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['$137K-$171K (Glassdoor est.)', '$75K-$131K (Glassdoor est.)',\n",
       "       '$79K-$131K (Glassdoor est.)', '$99K-$132K (Glassdoor est.)',\n",
       "       '$90K-$109K (Glassdoor est.)', '$101K-$165K (Glassdoor est.)',\n",
       "       '$56K-$97K (Glassdoor est.)', '$79K-$106K (Glassdoor est.)',\n",
       "       '$71K-$123K (Glassdoor est.)', '$90K-$124K (Glassdoor est.)',\n",
       "       '$91K-$150K (Glassdoor est.)', '$141K-$225K (Glassdoor est.)',\n",
       "       '$145K-$225K(Employer est.)', '$79K-$147K (Glassdoor est.)',\n",
       "       '$122K-$146K (Glassdoor est.)', '$112K-$116K (Glassdoor est.)',\n",
       "       '$110K-$163K (Glassdoor est.)', '$124K-$198K (Glassdoor est.)',\n",
       "       '$79K-$133K (Glassdoor est.)', '$69K-$116K (Glassdoor est.)',\n",
       "       '$31K-$56K (Glassdoor est.)', '$95K-$119K (Glassdoor est.)',\n",
       "       '$212K-$331K (Glassdoor est.)', '$66K-$112K (Glassdoor est.)',\n",
       "       '$128K-$201K (Glassdoor est.)', '$138K-$158K (Glassdoor est.)',\n",
       "       '$80K-$132K (Glassdoor est.)', '$87K-$141K (Glassdoor est.)',\n",
       "       '$92K-$155K (Glassdoor est.)', '$105K-$167K (Glassdoor est.)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df['Salary Estimate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_salary_estimate_feature(value):\n",
    "    \"\"\"\n",
    "    Converts a salary range from the format '$XK-$YK (Glassdoor est.)' to a simplified \n",
    "    format 'X-Y' by extracting the lower and upper bounds of the salary range.\n",
    "\n",
    "    Parameters:\n",
    "    ---------------\n",
    "    value (str): \n",
    "        A string representing the salary range, e.g., '$137K-$171K (Glassdoor est.)'.\n",
    "\n",
    "    Returns:\n",
    "    ---------------\n",
    "    str: \n",
    "        A string representing the simplified salary range, e.g., '137-171'.\n",
    "    \"\"\"\n",
    "    match = re.search(r'\\$(\\d+)(?:K)-\\$(\\d+)(?:K)', value)\n",
    "    return f'{match.group(1)}-{match.group(2)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_df['Salary Estimate'] = cleaning_df['Salary Estimate'].apply(convert_salary_estimate_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['137-171', '75-131', '79-131', '99-132', '90-109', '101-165',\n",
       "       '56-97', '79-106', '71-123', '90-124', '91-150', '141-225',\n",
       "       '145-225', '79-147', '122-146', '112-116', '110-163', '124-198',\n",
       "       '79-133', '69-116', '31-56', '95-119', '212-331', '66-112',\n",
       "       '128-201', '138-158', '80-132', '87-141', '92-155', '105-167'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df['Salary Estimate'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Job Description Feature`\n",
    "\n",
    "The Job Description feature contains detailed textual descriptions of job roles, responsibilities, qualifications, and other relevant information for each job posting. These descriptions vary widely in content, often including specific technical skills, required qualifications, and company values. The goal is to provide a comprehensive overview of the job, the company, and the expectations for the role.\n",
    "\n",
    "Given the highly variable nature of these descriptions (such as detailed healthcare analytics roles, IT security roles, or consulting positions), no cleaning or modifications were made to this feature. The raw text was retained for further analysis as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Description\\n\\nThe Senior Data Scientist is responsible for defining, building, and improving statistical models to improve business processes and outcomes in one or more healthcare domains such as Clinical, Enrollment, Claims, and Finance. As part of the broader analytics team, Data Scientist will gather and analyze data to solve and address complex business problems and evaluate scenarios to make predictions on future outcomes and work with the business to communicate and support decision-making. This position requires strong analytical skills and experience in analytic methods including multivariate regressions, hierarchical linear models, regression trees, clustering methods and other complex statistical techniques.\\n\\nDuties & Responsibilities:\\n\\n• Develops advanced statistical models to predict, quantify or forecast various operational and performance metrics in multiple healthcare domains\\n• Investigates, recommends, and initiates acquisition of new data resources from internal and external sources\\n• Works with multiple teams to support data collection, integration, and retention requirements based on business needs\\n• Identifies critical and emerging technologies that will support and extend quantitative analytic capabilities\\n• Collaborates with business subject matter experts to select relevant sources of information\\n• Develops expertise with multiple machine learning algorithms and data science techniques, such as exploratory data analysis and predictive modeling, graph theory, recommender systems, text analytics and validation\\n• Develops expertise with Healthfirst datasets, data repositories, and data movement processes\\n• Assists on projects/requests and may lead specific tasks within the project scope\\n• Prepares and manipulates data for use in development of statistical models\\n• Other duties as assigned\\n\\nMinimum Qualifications:\\n\\n-Bachelor's Degree\\n\\nPreferred Qualifications:\\n\\n- Master’s degree in Computer Science or Statistics\\nFamiliarity with major cloud platforms such as AWS and Azure\\nHealthcare Industry Experience\\n\\nMinimum Qualifications:\\n\\n-Bachelor's Degree\\n\\nPreferred Qualifications:\\n\\n- Master’s degree in Computer Science or Statistics\\nFamiliarity with major cloud platforms such as AWS and Azure\\nHealthcare Industry Experience\\n\\nWE ARE AN EQUAL OPPORTUNITY EMPLOYER. Applicants and employees are considered for positions and are evaluated without regard to mental or physical disability, race, color, religion, gender, national origin, age, genetic information, military or veteran status, sexual orientation, marital status or any other protected Federal, State/Province or Local status unrelated to the performance of the work involved.\\n\\nIf you have a disability under the Americans with Disability Act or a similar law, and want a reasonable accommodation to assist with your job search or application for employment, please contact us by sending an email to careers@Healthfirst.org or calling 212-519-1798 . In your email please include a description of the accommodation you are requesting and a description of the position for which you are applying. Only reasonable accommodation requests related to applying for a position within Healthfirst Management Services will be reviewed at the e-mail address and phone number supplied. Thank you for considering a career with Healthfirst Management Services.\\nEEO Law Poster and Supplement\\n\\n]]>\",\n",
       "       \"Secure our Nation, Ignite your Future\\n\\nJoin the top Information Technology and Analytic professionals in the industry to make invaluable contributions to our national security on a daily basis. In this innovative, self-contained, Big Data environment, the ManTech team is responsible for everything from infrastructure, to application development, to data science, to advanced analytics and beyond. The team is diverse, the questions are thought-provoking, and the opportunities for growth and advancement are numerous\\n\\nThe successful candidate will possess a diverse range of data-focused skills and experience, both technical and analytical. They will have a strong desire and capability for problem solving, data analysis and troubleshooting, analytical thinking, and experimentation.\\n\\nDuties, Tasks & Responsibilities\\nWorking with large, complex, and disparate data sets\\nDesigning and implementing innovative ways to analyze and exploit the Sponsors data holdings\\nResearching and reporting on a wide variety of Sponsor inquiries\\nRaising proactive inquiries to the Sponsor based on observations and proposed data analysis/exploitation\\nSolving difficult, non-routine problems by applying advanced analytical methodologies, and improving analytic methodologies\\nDeveloping custom searches\\nCommunicating and coordinating with internal and external partners as needed\\nRequired Experience, Skills, & Technologies\\n\\nThorough knowledge of appropriate analytic tools and methodologies in one or more of the following:\\nApplied mathematics (e.g. probability and statistics, formal modeling, computational social sciences)\\nComputer programming (e.g. programming languages, math/statistics packages, computer science, machine learning, scientific computing)\\nAbility to code or script in one or more general programming language\\nExperience with and theoretical understanding of algorithms for classification, regression, clustering, and anomaly detection\\nKnowledge of relational databases, including SQL and large-scale distributed systems (e.g. Hadoop)\\nExpertise with statistical data analysis (e.g. linear models, multivariate analysis, stochastic models, sampling methods)\\nDemonstrated effectiveness in collecting information and accurately representing/visualizing it to non-technical third parties\\nTS/SCI with Polygraph\\nBachelor of Science or equivalent and 12-15 years related experience, but will consider all levels of experience.\\nDesired Experience, Skills & Technologies\\nPrevious investigative experience using a combination of technical and analytic skills\\n#LI-DU1\\n\\nManTech International Corporation, as well as its subsidiaries proactively fulfills its role as an equal opportunity employer. We do not discriminate against any employee or applicant for employment because of race, color, sex, religion, age, sexual orientation, gender identity and expression, national origin, marital status, physical or mental disability, status as a Disabled Veteran, Recently Separated Veteran, Active Duty Wartime or Campaign Badge Veteran, Armed Forces Services Medal, or any other characteristic protected by law.\\n\\nIf you require a reasonable accommodation to apply for a position with ManTech through its online applicant system, please contact ManTech's Corporate EEO Department at (703) 218-6000. ManTech is an affirmative action/equal opportunity employer - minorities, females, disabled and protected veterans are urged to apply. ManTech's utilization of any external recruitment or job placement agency is predicated upon its full compliance with our equal opportunity/affirmative action policies. ManTech does not accept resumes from unsolicited recruiting firms. We pay no fees for unsolicited services.\\n\\nIf you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access http://www.mantech.com/careers/Pages/careers.aspx as a result of your disability. To request an accommodation please click careers@mantech.com and provide your name and contact information.\",\n",
       "       \"Overview\\n\\n\\nAnalysis Group is one of the largest international economics consulting firms, with more than 1,000 professionals across 14 offices in North America, Europe, and Asia. Since 1981, we have provided expertise in economics, finance, health care analytics, and strategy to top law firms, Fortune Global 500 companies, and government agencies worldwide. Our internal experts, together with our network of affiliated experts from academia, industry, and government, offer our clients exceptional breadth and depth of expertise.\\n\\nWe are currently seeking a Data Scientist to join our team. The ideal candidate should be passionate about working on cutting edge research and analytical services for Fortune 500 companies, global pharma/biotech firms and leaders in industries such as finance, energy and life sciences. The Data Scientist will be a contributing member to client engagements and have the opportunity to work with our network of world-class experts and thought leaders.\\n\\nJob Functions and Responsibilities\\n\\nThe candidate Data Scientist will help develop, maintain and teach new tools and methodologies related to data science and high performance computing. This position will also help Analysis Group in maintaining our leadership position in terms of advancing methodology and data analytics. The Data Scientist will be responsible for staying abreast of new developments in technology relating to data science, to share more broadly with Analysis Group.\\n\\nKey responsibilities for this position will include:\\nWorking with project teams to address data science/computing challenges\\nIdentifying opportunities for technology to enhance service offerings\\nActing as a resource and participating in client engagements and research as part of the project team\\nMaintaining up-to-date knowledge of computing tools, providing technical training and helping to grow the in-house knowledge base, specifically in a Linux environment\\nPresenting research at selected conferences\\nExamples of activities for the Data Scientist will include:\\nDeveloping data engineering and machine learning production systems for full stack data science projects\\nUsing natural language processing methodologies to work with EMR data, social media data and other unstructured data\\nOptimizing procedures for managing and accessing large databases (e.g., insurance claims, electronic health records, financial transactions)\\nCreating interactive analytics portals and data visualizations (e.g., using R/Shiny, Python/Flask, D3)\\nBuilding and maintaining high performance computing (HPC) tools on grid and cloud computing environments\\nDeveloping and reviewing software and packages in R, Python and other Object Oriented Languages\\nEstablishing optimized procedures for repetitive or computationally intensive tasks (C, C++, Cuda-C)\\nQualifications\\nStrong credentials and experience in database management and data visualization\\nSignificant experience working within a Linux environment required\\nBackground in Statistics/Econometrics or Biostatistics\\nIdeally PhD in Computer Science, Mathematics, Statistics, Economics or other relevant scientific degree with relevant experience. Other candidates with at least one year of experience in the field may also be considered\\nExcellent written and verbal communication skills\\nProject experience with R and/or Python\\nFamiliar with online/cloud computing/storage (e.g., AWS)\\nDemonstrated experience working on project teams and collaborating with others\\nSCIENTIFIQUE DES DONNÉES\\n\\n*L’utilisation du genre masculin sert uniquement à alléger le texte et est utilisé ici en tant que genre neutre\\n\\nSurvol\\n\\nGroupe d’analyse ltée est l’une des plus grandes firmes de services-conseils en économie, comptant plus de 950 professionnels répartis dans 14 bureaux en Amérique du Nord, en Europe et en Asie. Depuis 1981, nous offrons notre expertise en matière de stratégie, d’économie, de finance et d’analyse dans le domaine des soins de santé aux grands cabinets d’avocats, aux sociétés Fortune Global 500 et aux agences gouvernementales du monde entier. Nos professionnels en poste conjugués à notre réseau de spécialistes affiliés issus d’universités, d’industries spécifiques et d’organismes gouvernementaux procurent à notre clientèle un savoir-faire d’une portée et d’une profondeur exceptionnelles.\\n\\nNous sommes présentement à la recherche d'un Scientifique des données (« Data Scientist ») pour se joindre à notre équipe. Le candidat idéal devrait être passionné par la recherche de pointe et les services analytiques pour les entreprises Fortune 500, les entreprises pharmaceutiques et biotechnologiques mondiales et les chefs de file dans des secteurs de la finance, l'énergie et les sciences de la vie. Le Scientifique des données sera un membre contributeur aux mandats des clients et aura l'occasion de travailler avec notre réseau d'experts et de leaders d'opinion de classe mondiale.\\n\\nDescription du poste et des responsabilités\\n\\nLe scientifique des données aidera à développer, maintenir et enseigner de nouveaux outils et méthodologies liés à la science des données (« Data Science ») et au HPC. Ce poste aidera également le Groupe d'analyse à maintenir sa position de chef de file en ce qui a trait à l'avancement de la méthodologie et de l'analyse des données. Le scientifique des données sera chargé de se tenir au courant des nouveaux développements technologiques liés à la science des données, afin de les partager plus largement avec le Groupe d'analyse.\\n\\nLes principales responsabilités de ce poste comprendront:\\n\\n- Collaborer avec les consultants pour relever les défis de la science des données et de sciences informatiques\\n\\n- Agir à titre de ressource et participer aux mandats et à la recherche en tant que membre de l'équipe de projet\\n\\n- Maintenir à jour les connaissances sur les outils informatiques, fournir une formation technique et aider à développer la base de connaissances interne, notamment dans un environnement Linux\\n\\n- Présenter la recherche à des conférences choisies\\n\\nExemples de tâches du scientifique des données :\\n\\n- Développement de systèmes de production en ingénierie des données ainsi qu’en apprentissage machine pour des projets de science des données full stack\\n\\n- Utiliser des méthodologies NLP pour travailler avec les données médicales électroniques, les données des médias sociaux et d'autres données non structures\\n\\n- Optimiser les procédures de gestion et d'accès aux grandes bases de données (ex. réclamations d'assurance, dossiers de santé électroniques, transactions financières)\\n\\n- Création de portails d'analyse interactifs et de visualisations de données (par exemple, en utilisant R/Shiny, Python/Flask, D3)\\n\\n- Construire et maintenir des outils de calcul de haute performance (HPC).\\n\\n- Développement et révision de codes en R, Python et autres langages\\n\\n- Mise en place de procédures optimisées pour les tâches répétitives ou intensives en calcul (C, C++, Cuda-C)\\n\\nQualifications requises\\n\\n- Solides références et expérience dans la gestion de bases de données et de la visualisation de données\\n\\n- Expérience de travail significative dans un environnement Linux requise\\n\\n- Expérience antérieure en statistique/économétrie ou bio-statistique\\n\\n- Idéalement, être titulaire d'un doctorat en sciences informatiques, en mathématiques, en statistique, en économie ou d'un autre diplôme scientifique pertinent et posséder une expérience pertinente. Les candidats ayant au moins un an d'expérience dans le domaine peuvent également être considérés.\\n\\n- Excellentes aptitudes de communication écrite et verbale\\n\\n- Expérience de projet avec R et/ou Python\\n\\n- Familiarité avec l'informatique en ligne/info nuagique et le stockage (AWS)\\n\\n- Expérience de travail démontrée au sein d'équipes de projet et de collaboration avec d'autres personnes\\n\\n\\xad\\nEqual Opportunity Employer/Protected Veterans/Individuals with Disabilities.\\nPlease view Equal Employment Opportunity Posters provided by OFCCP here.\\nThe contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor's legal duty to furnish information. 41 CFR 60-1.35(c)\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df['Job Description'].unique()[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Rating Feature`\n",
    "\n",
    "The Rating feature contains values where negative ratings were present, which are handled by the cleaning_ratings function. This function checks if the rating is below zero and converts it to 0, while leaving all other ratings unchanged. After applying this cleaning process, the ratings are updated to reflect non-negative values only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.1,  4.2,  3.8,  3.5,  2.9,  3.9,  4.4,  3.6,  4.5,  4.7,  3.7,\n",
       "        3.4,  4.1,  3.2,  4.3,  2.8,  5. ,  4.8,  3.3,  2.7,  2.2,  2.6,\n",
       "        4. ,  2.5,  4.9,  2.4, -1. ,  2.3,  4.6,  3. ,  2.1,  2. ])"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df['Rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df['Rating'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_ratings(value):\n",
    "    \"\"\"\n",
    "    Cleans the rating values by replacing any negative ratings with 0, \n",
    "    while leaving positive ratings unchanged.\n",
    "\n",
    "    Parameters:\n",
    "    -------------\n",
    "    value (float): \n",
    "        The rating value to be cleaned. It can be a positive float, zero, or a negative value.\n",
    "\n",
    "    Returns:\n",
    "    -------------\n",
    "    float: \n",
    "        A cleaned rating value. Negative values are replaced with 0, while other values remain the same.\n",
    "    \"\"\"\n",
    "    if value < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_df['Rating'] = cleaning_df['Rating'].apply(cleaning_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.1, 4.2, 3.8, 3.5, 2.9, 3.9, 4.4, 3.6, 4.5, 4.7, 3.7, 3.4, 4.1,\n",
       "       3.2, 4.3, 2.8, 5. , 4.8, 3.3, 2.7, 2.2, 2.6, 4. , 2.5, 4.9, 2.4,\n",
       "       0. , 2.3, 4.6, 3. , 2.1, 2. ])"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df['Rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([154, 158, 230, 282, 285, 290, 319, 322, 329, 338, 351, 357, 358, 359,\n",
       "       360, 361, 362, 388, 389, 409, 411, 425, 430, 431, 437, 438, 440, 457,\n",
       "       459, 495, 496, 497, 498, 499, 500, 504, 519, 524, 555, 568, 613, 615,\n",
       "       637, 650, 656, 657, 660, 664, 668, 669],\n",
       "      dtype='int64')"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df[cleaning_df['Rating'] == 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Job Title', 'Salary Estimate', 'Job Description', 'Rating',\n",
       "       'Company Name', 'Location', 'Headquarters', 'Size', 'Founded',\n",
       "       'Type of ownership', 'Industry', 'Sector', 'Revenue', 'Competitors'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Company Name Feature`\n",
    "\n",
    "The Company Name feature originally contained both company names and ratings separated by a newline character (\\n). The clean_company_name_feature function cleans this feature by removing the newline character and any text following it. After applying this transformation, the Company Name column now contains only the company names, without any extraneous information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Healthfirst\\n3.1', 'ManTech\\n4.2', 'Analysis Group\\n3.8',\n",
       "       'INFICON\\n3.5', 'Affinity Solutions\\n2.9', 'HG Insights\\n4.2',\n",
       "       'Novartis\\n3.9', 'iRobot\\n3.5', 'Intuit - Data\\n4.4',\n",
       "       'XSELL Technologies\\n3.6', 'Novetta\\n4.5', '1904labs\\n4.7',\n",
       "       'PNNL\\n3.7', 'Old World Industries\\n3.1',\n",
       "       'Mathematica Policy Research\\n3.4',\n",
       "       'Guzman & Griffin Technologies (GGTI)\\n4.4',\n",
       "       'Upside Business Travel\\n4.1', 'Buckman\\n3.5',\n",
       "       'Insight Enterprises, Inc.\\n4.2', 'Tower Health\\n3.5',\n",
       "       'Triplebyte\\n3.2', 'PulsePoint\\n4.3', 'Exponent\\n3.5',\n",
       "       'Guardian Life\\n3.5',\n",
       "       'Spectrum Communications and Consulting\\n3.4',\n",
       "       'Oversight Systems\\n4.7', 'LSQ\\n4.2',\n",
       "       'MIT Lincoln Laboratory\\n3.8', 'Kingfisher Systems\\n4.5',\n",
       "       'Formation\\n2.8', 'Cohere Health\\n5.0', 'Acuity Insurance\\n4.8',\n",
       "       'Chef\\n3.6', 'Puget Sound Energy\\n3.3', 'Sandhills Global\\n2.7',\n",
       "       'A Place for Mom\\n2.7', 'Great-Circle Technologies\\n2.2',\n",
       "       'Edmunds.com\\n3.4', 'Cambridge Associates, LLC\\n3.1',\n",
       "       'Liberty Mutual Insurance\\n3.4', 'Cenlar\\n2.6',\n",
       "       'Arsenal Biosciences\\n5.0', 'Eversight\\n4.2', 'Pfizer\\n4.1',\n",
       "       'Klaviyo\\n4.8', 'Intellectual Ventures\\n3.3', 'GovTech\\n3.7',\n",
       "       'Quick Base\\n4.3', 'Giving Assistant\\n4.8', 'Takeda\\n3.7',\n",
       "       'Netskope\\n4.0', 'IT Concepts\\n4.8', 'iSeatz\\n3.5',\n",
       "       'Summa Health System\\n3.7', 'Benson Hill\\n3.5', 'Twitter\\n4.1',\n",
       "       'Postmates - Corporate HQ\\n3.2', 'Envision LLC\\n4.5',\n",
       "       'Swiss Re\\n3.8', 'Systems & Technology Research\\n4.5',\n",
       "       'Dermalogica\\n3.8', 'Bayview Asset Management\\n3.7',\n",
       "       'Via Transportation\\n3.7', 'Grid Dynamics\\n4.0',\n",
       "       'Tempus Labs\\n3.3', 'CareDx\\n2.5', 'IZEA\\n4.2', 'Autodesk\\n4.0',\n",
       "       'Caterpillar\\n3.7', 'New England Biolabs\\n4.9',\n",
       "       'Allied Solutions\\n3.4', 'The Knot Worldwide\\n3.5',\n",
       "       'IFG Companies\\n2.9', 'Amyris\\n3.3', 'AstraZeneca\\n4.0',\n",
       "       'Powertek\\n3.6', 'Object Partners\\n4.7', 'The Mom Project\\n4.9',\n",
       "       'Lightspeed Systems\\n4.3', 'Stripe\\n4.0',\n",
       "       'Comprehensive Healthcare\\n2.6',\n",
       "       'Fullpower Technologies, Inc.\\n4.5', 'Mars\\n3.9',\n",
       "       'NuWave Solutions\\n4.4', 'Merrick Bank\\n3.6', 'QOMPLX\\n3.5',\n",
       "       'GutCheck\\n3.8', 'Inter-American Development Bank\\n3.5',\n",
       "       'Avlino\\n4.9', 'Stratagem Group\\n4.4', 'Evidation\\n4.1',\n",
       "       'Tecolote Research\\n3.8', 'Tivity Health\\n3.2', 'hc1\\n2.9',\n",
       "       'HP Inc.\\n4.1', 'SAIC\\n3.7', 'AllianceBernstein\\n3.2',\n",
       "       'Big Huge Games\\n4.9', 'Maxar Technologies\\n3.5',\n",
       "       'Phantom AI\\n5.0', 'Noblis\\n4.0', 'Spring Health\\n3.6',\n",
       "       'ClearEdge\\n4.0', 'GetWellNetwork\\n4.8', 'TACG Solutions\\n4.5',\n",
       "       'Scoop\\n4.7', 'Montway Inc\\n3.4', 'Juniper Networks\\n3.8',\n",
       "       'Notion Labs\\n5.0', 'Lendio\\n4.9', 'Direct Agents\\n4.4',\n",
       "       'NAVEX Global\\n3.3', 'Upstart\\n4.2', 'AppLovin\\n4.8',\n",
       "       'ISO New England\\n3.8', 'Relativity\\n3.7', 'Tempo Automation\\n3.3',\n",
       "       'MITRE\\n3.3', 'Expedition Technology, Inc.\\n5.0', 'Evidera\\n3.8',\n",
       "       'Plymouth Rock Assurance\\n3.4', 'Crown Bioscience\\n2.4',\n",
       "       'GNS Healthcare\\n2.9', 'OneMagnify\\n4.4', 'SPECTRUM\\n2.9',\n",
       "       'Advanced BioScience Laboratories\\n2.7',\n",
       "       'Procore Technologies\\n4.2', 'Ritedose\\n3.5',\n",
       "       'Covid-19 Search Partners', 'bioMérieux\\n4.2',\n",
       "       'Radical Convergence', 'Leidos\\n3.5', 'Demandbase\\n4.5',\n",
       "       'Shelter Insurance\\n4.1', 'USAC\\n2.7',\n",
       "       'General Dynamics Information Technology\\n3.4', 'Offerpad\\n4.4',\n",
       "       'Magna International Inc.\\n3.5', 'United BioSource\\n2.3',\n",
       "       'Kelly\\n3.4', 'C3.ai\\n4.7', 'Quartet Health\\n3.9',\n",
       "       'Midland Credit Management\\n3.3',\n",
       "       'Resurgent Capital Services\\n4.4', 'webfx.com\\n4.7',\n",
       "       'Argo Group US\\n3.5', 'BWX Technologies\\n3.3', 'Life360\\n3.9',\n",
       "       'MassMutual\\n3.7', 'Natera\\n3.9', 'Genentech\\n4.0', 'Ntrepid\\n4.2',\n",
       "       'Constant Contact\\n3.6', 'Sage Intacct\\n4.7',\n",
       "       'Shape Security\\n4.1', 'SkillSoniq\\n5.0', 'Joby Aviation\\n4.3',\n",
       "       \"Cook Children's Health Care System\\n3.8\",\n",
       "       'Rubius Therapeutics\\n3.8', 'GreatAmerica Financial Services\\n4.6',\n",
       "       'Coverent\\n4.1', 'Mteq\\n3.7', 'Rocket Lawyer\\n4.4',\n",
       "       'Alion Science & Technology\\n3.6', 'Protolabs\\n3.7',\n",
       "       'Quest Integrity\\n2.9', 'Phoenix Operations Group\\n5.0',\n",
       "       'Dice.com\\n3.4', 'Southwest Research Institute\\n3.9',\n",
       "       'The Buffalo Group\\n4.3',\n",
       "       'Central California Alliance for Health\\n3.5',\n",
       "       'Security Finance Corporation of Spartanburg\\n3.1',\n",
       "       'Opendoor\\n3.6', 'Global Data Management Inc\\n4.5',\n",
       "       'Photon Infotech\\n3.0', 'REE\\n5.0',\n",
       "       'Riverside Research Institute\\n3.6', 'T. Rowe Price\\n3.6',\n",
       "       'Encode, Inc.', 'Brighthouse Financial\\n3.8',\n",
       "       'II-VI Incorporated\\n3.3', 'Surya Systems\\n4.6', 'PayPal\\n3.8',\n",
       "       'Predictive Research Inc\\n3.9', '1010data\\n3.1', 'Gigya\\n3.6',\n",
       "       'Genesis Research\\n5.0', 'Sanofi\\n3.7', 'XPO Logistics\\n3.7',\n",
       "       'Trace Data\\n3.9', 'Descript\\n4.3',\n",
       "       'Rincon Research Corporation\\n4.2', 'Better Hire\\n4.0',\n",
       "       'Parker Hannifin\\n3.3', 'Gallup\\n4.1', 'Insider Inc\\n3.3',\n",
       "       'Rapid Value Solutions\\n3.9', 'Battelle\\n3.1',\n",
       "       'The Drive Media, Inc.\\n5.0',\n",
       "       'Pacific Northwest National Laboratory\\n3.7',\n",
       "       'US Pharmacopeia\\n3.2', 'Itlize Global\\n4.6', 'eBay\\n3.5',\n",
       "       'Paige\\n5.0', 'ABIOMED\\n4.1', 'Comcast\\n3.5',\n",
       "       'Metronome, LLC\\n3.2', 'Lawrence Livermore National Lab\\n4.7',\n",
       "       'FHLBank Pittsburgh\\n3.8', 'Jacobs\\n3.6',\n",
       "       'Underwriters Laboratories\\n3.3', 'Altus Group\\n3.7', 'Jobot\\n5.0',\n",
       "       'Trovetechs Inc', 'Oshkosh Corporation\\n4.2', 'Mackin\\n3.4',\n",
       "       'PETADATA', 'VBeyond Corporation\\n4.4', 'Take-Two\\n3.7',\n",
       "       'Colony Brands\\n3.7', 'Capio Group\\n4.1', 'SleePare\\n3.4',\n",
       "       'ShorePoint\\n4.5', 'Dolphin\\n3.5', 'TE Connectivity\\n3.6',\n",
       "       'State of Virginia\\n3.2', 'TA Digital\\n3.7',\n",
       "       'Market America Inc\\n4.0', 'TrueAccord\\n3.4',\n",
       "       'ALTA IT Services\\n3.9', 'Kollasoft Inc.\\n3.2',\n",
       "       'ASRC Federal Holding Company\\n3.4', 'Adwait Algorithm\\n4.4',\n",
       "       'Cambridge FX\\n3.5', 'Metromile\\n3.8', 'Criteo\\n3.9',\n",
       "       'Advance Sourcing Concepts\\n3.4', 'Enterprise Solutions Inc\\n3.8',\n",
       "       'Microagility', 'Conch Technologies, Inc\\n4.6', 'GSK\\n3.9',\n",
       "       'Rainmaker Resources, LLC', '22nd Century Technologies\\n3.7',\n",
       "       'Huxley\\n3.3', 'FM Systems\\n3.4', 'B4Corp',\n",
       "       'Blue Cross and Blue Shield of North Carolina\\n3.7',\n",
       "       'Jane Street\\n4.8', 'SSATI\\n5.0',\n",
       "       'Solving IT International Inc\\n3.4',\n",
       "       'The Davey Tree Expert Company\\n3.3', 'Centauri\\n4.6',\n",
       "       'Stride Search', 'Software Engineering Institute\\n2.6',\n",
       "       'TechProjects\\n4.8', '7Park Data\\n3.9',\n",
       "       'Ameritas Life Insurance Corp\\n3.0', 'Western Digital\\n3.5',\n",
       "       'Shimento, Inc.\\n2.9', 'Averity\\n5.0', 'Praxis Engineering\\n4.7',\n",
       "       'Point72 Ventures',\n",
       "       'Johns Hopkins University Applied Physics Laboratory\\n4.5',\n",
       "       'Cambridge Mobile Telematics\\n4.9', 'Blend360\\n4.6',\n",
       "       'Nolij Consulting\\n3.9', 'Hatch Data Inc',\n",
       "       'Compass Consulting Group\\n4.7', 'SolutionIT, Inc.\\n4.4',\n",
       "       'Perspecta\\n3.2', 'Smith Hanley Associates\\n4.5',\n",
       "       'Allen Institute\\n3.5', 'Eliassen Group\\n4.4',\n",
       "       'Bayside Solutions\\n3.1', 'Evolve Vacation Rental\\n3.5',\n",
       "       'AgreeYa Solutions\\n3.8', 'Carolina Power & Light Co\\n3.7',\n",
       "       'New Iron Group, Inc.\\n5.0', 'Travelers\\n4.0', 'Twitch\\n3.6',\n",
       "       'Biogen\\n3.6', 'HireAi', 'Mentor Graphics\\n4.1',\n",
       "       'WCG (WIRB-Copernicus Group)\\n3.6',\n",
       "       'Visionary Integration Professionals\\n4.3', 'Dynetics\\n4.0',\n",
       "       'Navy Federal Credit Union\\n3.9',\n",
       "       'Exact Sciences Corporation\\n4.0',\n",
       "       'Community Behavioral Health\\n3.6', 'Reynolds American\\n3.3',\n",
       "       'LifeOmic\\n5.0', 'Visionist, Inc.\\n4.9', 'Navio',\n",
       "       'Concerto HealthAI\\n3.3', 'Evolvinc', 'PROPRIUS\\n5.0',\n",
       "       'TECHNOCRAFT Solutions\\n3.4', 'Latitude, Inc.\\n4.1',\n",
       "       'Royce Geospatial\\n5.0', 'CyberCoders\\n4.2',\n",
       "       'Booz Allen Hamilton Inc.\\n3.7', 'Burns & McDonnell\\n3.8',\n",
       "       'InvenTech Info\\n4.8', 'Robert Half\\n3.5',\n",
       "       'Conflux Systems Inc.\\n4.5', 'Voice\\n3.4',\n",
       "       'Falcon IT & Staffing Solutions', 'DataLab USA\\n3.6',\n",
       "       'Werner Enterprises Inc\\n3.1', 'PeopleCom\\n5.0',\n",
       "       'VANTA Partners\\n5.0', 'Blue Icy Water, LLC',\n",
       "       \"Farmer's Business Network, Inc.\\n3.5\", 'Sonde Health',\n",
       "       'Maxiom\\n5.0', 'Change Healthcare\\n2.7', 'DCS Corp\\n4.1',\n",
       "       'Hive (CA)\\n2.1', 'Hackensack Meridian Health\\n3.3',\n",
       "       'Net2Source Inc.\\n3.2', 'The Trade Desk\\n3.2', 'IBM\\n3.7',\n",
       "       'Knowesis Inc.\\n4.4', 'MoTek Technologies\\n3.1', 'HPOne\\n3.5',\n",
       "       'Blue Cloak LLC', 'TBWA\\\\Chiat\\\\Day\\n2.7',\n",
       "       'ThreeBridge Solutions\\n3.5', 'Numeric, LLC\\n3.2',\n",
       "       'Centraprise\\n4.2', 'DW Simpson\\n4.2', 'LinQuest\\n3.9',\n",
       "       'Trexquant Investment\\n4.0', 'Fleetcor\\n3.7',\n",
       "       'Radiant Digital\\n4.5', 'Child Care Aware of America\\n2.8',\n",
       "       'IntelliPro Group Inc.\\n4.1', 'USI\\n3.4', 'Apex Systems\\n3.9',\n",
       "       'Pragmatics, Inc.\\n2.9', 'Crossover Health\\n3.5',\n",
       "       'Lorven Technologies Inc\\n4.0', 'Gap Inc.\\n3.5',\n",
       "       'Tygart Technology, Inc\\n4.7', 'Murray Resources\\n4.6',\n",
       "       'New York Technology Partners\\n4.0',\n",
       "       'Two95 International Inc.\\n4.0', 'Sophinea', 'CRS Group\\n4.7',\n",
       "       'Blackstone Talent Group\\n3.5', 'Roche\\n4.1',\n",
       "       'Creative Circle\\n3.6', 'Blue Horizon Tek Solutions\\n5.0',\n",
       "       'Sharpedge Solutions Inc\\n4.7',\n",
       "       'Alaka`ina Foundation Family of Companies\\n3.6',\n",
       "       'Hexagon US Federal\\n2.7', 'Monte Rosa Therapeutics',\n",
       "       'Comtech Global Inc\\n4.0', 'Aveshka, Inc.\\n3.8',\n",
       "       '10x Genomics\\n4.2', 'CompuForce', '1-800-Flowers\\n2.7',\n",
       "       'Aptive\\n3.5', 'JCD Staffing\\n5.0', 'Thumbtack\\n3.9',\n",
       "       'MILVETS Systems Technology, Inc.\\n3.4', 'Apple\\n4.1',\n",
       "       'Kforce\\n4.1', 'OppLoans\\n4.4', 'Brillient\\n3.9',\n",
       "       'Xator Corporation\\n2.9', 'HAN IT Staffing Inc.\\n4.6',\n",
       "       'Infinitive Inc\\n3.4', 'New Relic\\n4.7', 'ICW Group\\n3.3',\n",
       "       'NYSTEC\\n3.8', 'E3 Federal Solutions\\n4.5', 'Peraton\\n3.4',\n",
       "       'Group O\\n3.1', 'CaptiveAire\\n4.1', 'Temboo\\n3.9', 'Kibo',\n",
       "       'AeroVironment\\n4.2', 'Applied Research Laboratories\\n3.8',\n",
       "       'Conagen\\n2.0', 'Alector\\n4.8', 'Homology Medicines, Inc.\\n4.4',\n",
       "       'Inland Empire Health Plan\\n3.3',\n",
       "       'Sandia National Laboratories\\n3.8', 'CIA\\n3.8',\n",
       "       'Maven Wave Partners\\n4.5', 'Ovative Group\\n4.3', 'Kognetics\\n3.6',\n",
       "       'Envision Healthcare\\n2.9', 'ConsumerTrack\\n3.2',\n",
       "       'Meridian Knowledge Solutions\\n4.4', 'UST Global\\n4.2',\n",
       "       'IMG Systems\\n3.2', 'Trident Systems Inc\\n3.4', 'GrainBridge, LLC',\n",
       "       'First Health Group\\n3.2', 'Sprezzatura Management Consulting',\n",
       "       'Progress Rail, A Caterpillar Company\\n2.8',\n",
       "       'Axiologic Solutions\\n4.5', 'Indigo Slate\\n3.0', 'Cubic\\n3.3',\n",
       "       'Advanced Bio-Logic Solutions Corp\\n4.0',\n",
       "       'Alignment Healthcare\\n3.5', 'WGSN\\n3.5',\n",
       "       'ISYS Technologies, Inc.\\n3.6', 'TransVoyant\\n3.0', 'Geotab\\n4.3',\n",
       "       'EGlobalTech\\n3.7', 'Central Business Solutions, Inc\\n3.0',\n",
       "       'KeHE Distributors\\n2.5', 'Moxie Software\\n3.0',\n",
       "       'Unicom Technologies INC\\n4.7', 'Americo Life\\n3.3',\n",
       "       'Tokio Marine HCC\\n3.3', 'CACI International\\n3.5',\n",
       "       'Berico Technologies', 'Kehe Food Distributors', 'Pactera Edge',\n",
       "       'Qurate Retail Group\\n3.6', 'A-Line Staffing Solutions\\n4.1',\n",
       "       'Clear Ridge Defense', 'Criterion Systems, Inc.\\n3.8',\n",
       "       'Foundation Medicine\\n4.0', 'TRANZACT\\n3.6', 'JKGT', 'AccessHope',\n",
       "       'ChaTeck Incorporated\\n5.0'], dtype=object)"
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df['Company Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_company_name_feature(value):\n",
    "    \"\"\"\n",
    "    Cleans the input string by removing the newline character ('\\n') and any text that follows it.\n",
    "\n",
    "    Parameters:\n",
    "    -------------\n",
    "    value (str): \n",
    "        A string containing company names and additional information after a newline character.\n",
    "\n",
    "    Returns:\n",
    "    -------------\n",
    "    str: \n",
    "        A cleaned version of the input string with the part after the newline removed.\n",
    "    \"\"\"\n",
    "    return re.sub(r'\\n.*', '', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_df['Company Name'] = cleaning_df['Company Name'].apply(clean_company_name_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Healthfirst', 'ManTech', 'Analysis Group', 'INFICON',\n",
       "       'Affinity Solutions', 'HG Insights', 'Novartis', 'iRobot',\n",
       "       'Intuit - Data', 'XSELL Technologies', 'Novetta', '1904labs',\n",
       "       'PNNL', 'Old World Industries', 'Mathematica Policy Research',\n",
       "       'Guzman & Griffin Technologies (GGTI)', 'Upside Business Travel',\n",
       "       'Buckman', 'Insight Enterprises, Inc.', 'Tower Health',\n",
       "       'Triplebyte', 'PulsePoint', 'Exponent', 'Guardian Life',\n",
       "       'Spectrum Communications and Consulting', 'Oversight Systems',\n",
       "       'LSQ', 'MIT Lincoln Laboratory', 'Kingfisher Systems', 'Formation',\n",
       "       'Cohere Health', 'Acuity Insurance', 'Chef', 'Puget Sound Energy',\n",
       "       'Sandhills Global', 'A Place for Mom', 'Great-Circle Technologies',\n",
       "       'Edmunds.com', 'Cambridge Associates, LLC',\n",
       "       'Liberty Mutual Insurance', 'Cenlar', 'Arsenal Biosciences',\n",
       "       'Eversight', 'Pfizer', 'Klaviyo', 'Intellectual Ventures',\n",
       "       'GovTech', 'Quick Base', 'Giving Assistant', 'Takeda', 'Netskope',\n",
       "       'IT Concepts', 'iSeatz', 'Summa Health System', 'Benson Hill',\n",
       "       'Twitter', 'Postmates - Corporate HQ', 'Envision LLC', 'Swiss Re',\n",
       "       'Systems & Technology Research', 'Dermalogica',\n",
       "       'Bayview Asset Management', 'Via Transportation', 'Grid Dynamics',\n",
       "       'Tempus Labs', 'CareDx', 'IZEA', 'Autodesk', 'Caterpillar',\n",
       "       'New England Biolabs', 'Allied Solutions', 'The Knot Worldwide',\n",
       "       'IFG Companies', 'Amyris', 'AstraZeneca', 'Powertek',\n",
       "       'Object Partners', 'The Mom Project', 'Lightspeed Systems',\n",
       "       'Stripe', 'Comprehensive Healthcare',\n",
       "       'Fullpower Technologies, Inc.', 'Mars', 'NuWave Solutions',\n",
       "       'Merrick Bank', 'QOMPLX', 'GutCheck',\n",
       "       'Inter-American Development Bank', 'Avlino', 'Stratagem Group',\n",
       "       'Evidation', 'Tecolote Research', 'Tivity Health', 'hc1',\n",
       "       'HP Inc.', 'SAIC', 'AllianceBernstein', 'Big Huge Games',\n",
       "       'Maxar Technologies', 'Phantom AI', 'Noblis', 'Spring Health',\n",
       "       'ClearEdge', 'GetWellNetwork', 'TACG Solutions', 'Scoop',\n",
       "       'Montway Inc', 'Juniper Networks', 'Notion Labs', 'Lendio',\n",
       "       'Direct Agents', 'NAVEX Global', 'Upstart', 'AppLovin',\n",
       "       'ISO New England', 'Relativity', 'Tempo Automation', 'MITRE',\n",
       "       'Expedition Technology, Inc.', 'Evidera',\n",
       "       'Plymouth Rock Assurance', 'Crown Bioscience', 'GNS Healthcare',\n",
       "       'OneMagnify', 'SPECTRUM', 'Advanced BioScience Laboratories',\n",
       "       'Procore Technologies', 'Ritedose', 'Covid-19 Search Partners',\n",
       "       'bioMérieux', 'Radical Convergence', 'Leidos', 'Demandbase',\n",
       "       'Shelter Insurance', 'USAC',\n",
       "       'General Dynamics Information Technology', 'Offerpad',\n",
       "       'Magna International Inc.', 'United BioSource', 'Kelly', 'C3.ai',\n",
       "       'Quartet Health', 'Midland Credit Management',\n",
       "       'Resurgent Capital Services', 'webfx.com', 'Argo Group US',\n",
       "       'BWX Technologies', 'Life360', 'MassMutual', 'Natera', 'Genentech',\n",
       "       'Ntrepid', 'Constant Contact', 'Sage Intacct', 'Shape Security',\n",
       "       'SkillSoniq', 'Joby Aviation',\n",
       "       \"Cook Children's Health Care System\", 'Rubius Therapeutics',\n",
       "       'GreatAmerica Financial Services', 'Coverent', 'Mteq',\n",
       "       'Rocket Lawyer', 'Alion Science & Technology', 'Protolabs',\n",
       "       'Quest Integrity', 'Phoenix Operations Group', 'Dice.com',\n",
       "       'Southwest Research Institute', 'The Buffalo Group',\n",
       "       'Central California Alliance for Health',\n",
       "       'Security Finance Corporation of Spartanburg', 'Opendoor',\n",
       "       'Global Data Management Inc', 'Photon Infotech', 'REE',\n",
       "       'Riverside Research Institute', 'T. Rowe Price', 'Encode, Inc.',\n",
       "       'Brighthouse Financial', 'II-VI Incorporated', 'Surya Systems',\n",
       "       'PayPal', 'Predictive Research Inc', '1010data', 'Gigya',\n",
       "       'Genesis Research', 'Sanofi', 'XPO Logistics', 'Trace Data',\n",
       "       'Descript', 'Rincon Research Corporation', 'Better Hire',\n",
       "       'Parker Hannifin', 'Gallup', 'Insider Inc',\n",
       "       'Rapid Value Solutions', 'Battelle', 'The Drive Media, Inc.',\n",
       "       'Pacific Northwest National Laboratory', 'US Pharmacopeia',\n",
       "       'Itlize Global', 'eBay', 'Paige', 'ABIOMED', 'Comcast',\n",
       "       'Metronome, LLC', 'Lawrence Livermore National Lab',\n",
       "       'FHLBank Pittsburgh', 'Jacobs', 'Underwriters Laboratories',\n",
       "       'Altus Group', 'Jobot', 'Trovetechs Inc', 'Oshkosh Corporation',\n",
       "       'Mackin', 'PETADATA', 'VBeyond Corporation', 'Take-Two',\n",
       "       'Colony Brands', 'Capio Group', 'SleePare', 'ShorePoint',\n",
       "       'Dolphin', 'TE Connectivity', 'State of Virginia', 'TA Digital',\n",
       "       'Market America Inc', 'TrueAccord', 'ALTA IT Services',\n",
       "       'Kollasoft Inc.', 'ASRC Federal Holding Company',\n",
       "       'Adwait Algorithm', 'Cambridge FX', 'Metromile', 'Criteo',\n",
       "       'Advance Sourcing Concepts', 'Enterprise Solutions Inc',\n",
       "       'Microagility', 'Conch Technologies, Inc', 'GSK',\n",
       "       'Rainmaker Resources, LLC', '22nd Century Technologies', 'Huxley',\n",
       "       'FM Systems', 'B4Corp',\n",
       "       'Blue Cross and Blue Shield of North Carolina', 'Jane Street',\n",
       "       'SSATI', 'Solving IT International Inc',\n",
       "       'The Davey Tree Expert Company', 'Centauri', 'Stride Search',\n",
       "       'Software Engineering Institute', 'TechProjects', '7Park Data',\n",
       "       'Ameritas Life Insurance Corp', 'Western Digital',\n",
       "       'Shimento, Inc.', 'Averity', 'Praxis Engineering',\n",
       "       'Point72 Ventures',\n",
       "       'Johns Hopkins University Applied Physics Laboratory',\n",
       "       'Cambridge Mobile Telematics', 'Blend360', 'Nolij Consulting',\n",
       "       'Hatch Data Inc', 'Compass Consulting Group', 'SolutionIT, Inc.',\n",
       "       'Perspecta', 'Smith Hanley Associates', 'Allen Institute',\n",
       "       'Eliassen Group', 'Bayside Solutions', 'Evolve Vacation Rental',\n",
       "       'AgreeYa Solutions', 'Carolina Power & Light Co',\n",
       "       'New Iron Group, Inc.', 'Travelers', 'Twitch', 'Biogen', 'HireAi',\n",
       "       'Mentor Graphics', 'WCG (WIRB-Copernicus Group)',\n",
       "       'Visionary Integration Professionals', 'Dynetics',\n",
       "       'Navy Federal Credit Union', 'Exact Sciences Corporation',\n",
       "       'Community Behavioral Health', 'Reynolds American', 'LifeOmic',\n",
       "       'Visionist, Inc.', 'Navio', 'Concerto HealthAI', 'Evolvinc',\n",
       "       'PROPRIUS', 'TECHNOCRAFT Solutions', 'Latitude, Inc.',\n",
       "       'Royce Geospatial', 'CyberCoders', 'Booz Allen Hamilton Inc.',\n",
       "       'Burns & McDonnell', 'InvenTech Info', 'Robert Half',\n",
       "       'Conflux Systems Inc.', 'Voice', 'Falcon IT & Staffing Solutions',\n",
       "       'DataLab USA', 'Werner Enterprises Inc', 'PeopleCom',\n",
       "       'VANTA Partners', 'Blue Icy Water, LLC',\n",
       "       \"Farmer's Business Network, Inc.\", 'Sonde Health', 'Maxiom',\n",
       "       'Change Healthcare', 'DCS Corp', 'Hive (CA)',\n",
       "       'Hackensack Meridian Health', 'Net2Source Inc.', 'The Trade Desk',\n",
       "       'IBM', 'Knowesis Inc.', 'MoTek Technologies', 'HPOne',\n",
       "       'Blue Cloak LLC', 'TBWA\\\\Chiat\\\\Day', 'ThreeBridge Solutions',\n",
       "       'Numeric, LLC', 'Centraprise', 'DW Simpson', 'LinQuest',\n",
       "       'Trexquant Investment', 'Fleetcor', 'Radiant Digital',\n",
       "       'Child Care Aware of America', 'IntelliPro Group Inc.', 'USI',\n",
       "       'Apex Systems', 'Pragmatics, Inc.', 'Crossover Health',\n",
       "       'Lorven Technologies Inc', 'Gap Inc.', 'Tygart Technology, Inc',\n",
       "       'Murray Resources', 'New York Technology Partners',\n",
       "       'Two95 International Inc.', 'Sophinea', 'CRS Group',\n",
       "       'Blackstone Talent Group', 'Roche', 'Creative Circle',\n",
       "       'Blue Horizon Tek Solutions', 'Sharpedge Solutions Inc',\n",
       "       'Alaka`ina Foundation Family of Companies', 'Hexagon US Federal',\n",
       "       'Monte Rosa Therapeutics', 'Comtech Global Inc', 'Aveshka, Inc.',\n",
       "       '10x Genomics', 'CompuForce', '1-800-Flowers', 'Aptive',\n",
       "       'JCD Staffing', 'Thumbtack', 'MILVETS Systems Technology, Inc.',\n",
       "       'Apple', 'Kforce', 'OppLoans', 'Brillient', 'Xator Corporation',\n",
       "       'HAN IT Staffing Inc.', 'Infinitive Inc', 'New Relic', 'ICW Group',\n",
       "       'NYSTEC', 'E3 Federal Solutions', 'Peraton', 'Group O',\n",
       "       'CaptiveAire', 'Temboo', 'Kibo', 'AeroVironment',\n",
       "       'Applied Research Laboratories', 'Conagen', 'Alector',\n",
       "       'Homology Medicines, Inc.', 'Inland Empire Health Plan',\n",
       "       'Sandia National Laboratories', 'CIA', 'Maven Wave Partners',\n",
       "       'Ovative Group', 'Kognetics', 'Envision Healthcare',\n",
       "       'ConsumerTrack', 'Meridian Knowledge Solutions', 'UST Global',\n",
       "       'IMG Systems', 'Trident Systems Inc', 'GrainBridge, LLC',\n",
       "       'First Health Group', 'Sprezzatura Management Consulting',\n",
       "       'Progress Rail, A Caterpillar Company', 'Axiologic Solutions',\n",
       "       'Indigo Slate', 'Cubic', 'Advanced Bio-Logic Solutions Corp',\n",
       "       'Alignment Healthcare', 'WGSN', 'ISYS Technologies, Inc.',\n",
       "       'TransVoyant', 'Geotab', 'EGlobalTech',\n",
       "       'Central Business Solutions, Inc', 'KeHE Distributors',\n",
       "       'Moxie Software', 'Unicom Technologies INC', 'Americo Life',\n",
       "       'Tokio Marine HCC', 'CACI International', 'Berico Technologies',\n",
       "       'Kehe Food Distributors', 'Pactera Edge', 'Qurate Retail Group',\n",
       "       'A-Line Staffing Solutions', 'Clear Ridge Defense',\n",
       "       'Criterion Systems, Inc.', 'Foundation Medicine', 'TRANZACT',\n",
       "       'JKGT', 'AccessHope', 'ChaTeck Incorporated'], dtype=object)"
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df['Company Name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Location Feature`\n",
    "\n",
    "The Location feature in the dataset initially contained location information in the form of city names, states, and sometimes additional details. To standardize this, two functions were applied. The job_location_new_feature function extracts the state abbreviation from location strings by checking whether they contain a city-state format (separated by a comma) or are just a state name, returning the state abbreviation in uppercase. The clean_location_feature function further refines the location by keeping only the state information, removing any city names. After applying these transformations, a new column, Location, is generated, containing the state names in a standardized format, with values such as 'NY', 'CA', 'TX', and 'FL', representing state abbreviations, or specific locations like 'Remote'. This ensures consistency and prepares the data for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['New York, NY', 'Chantilly, VA', 'Boston, MA', 'Newton, MA',\n",
       "       'Santa Barbara, CA', 'Cambridge, MA', 'Bedford, MA',\n",
       "       'San Diego, CA', 'Chicago, IL', 'Herndon, VA', 'Saint Louis, MO',\n",
       "       'Richland, WA', 'Northbrook, IL', 'Washington, DC', 'Remote',\n",
       "       'Memphis, TN', 'Plano, TX', 'West Grove, PA', 'Phoenix, AZ',\n",
       "       'Appleton, WI', 'Atlanta, GA', 'Orlando, FL', 'Lexington, MA',\n",
       "       'McLean, VA', 'San Francisco, CA', 'Sheboygan, WI',\n",
       "       'United States', 'Bothell, WA', 'Lincoln, NE', 'Overland Park, KS',\n",
       "       'Santa Monica, CA', 'Portsmouth, NH', 'Ewing, NJ',\n",
       "       'South San Francisco, CA', 'Palo Alto, CA', 'Bellevue, WA',\n",
       "       'New Orleans, LA', 'Akron, OH', 'Fort Wayne, IN', 'Woburn, MA',\n",
       "       'Carson, CA', 'Coral Gables, FL', 'Santa Clara, CA',\n",
       "       'Brisbane, CA', 'Winter Park, FL', 'Redwood City, CA',\n",
       "       'Peoria, IL', 'Ipswich, MA', 'Carmel, IN', 'Emeryville, CA',\n",
       "       'Gaithersburg, MD', 'Longmont, CO', 'Austin, TX', 'Yakima, WA',\n",
       "       'Santa Cruz, CA', 'Springfield, VA', 'Alexandria, VA', 'Utah',\n",
       "       'Reston, VA', 'Denver, CO', 'New Jersey', 'Aurora, CO',\n",
       "       'Hill AFB, UT', 'Chandler, AZ', 'Indianapolis, IN',\n",
       "       'Nashville, TN', 'Timonium, MD', 'Burlingame, CA',\n",
       "       'Annapolis Junction, MD', 'Bethesda, MD', 'Dayton, OH',\n",
       "       'Schaumburg, IL', 'Cupertino, CA', 'Lehi, UT', 'Culver City, CA',\n",
       "       'Lake Oswego, OR', 'San Mateo, CA', 'Holyoke, MA',\n",
       "       'Woodbridge, NJ', 'Dearborn, MI', 'Maryland Heights, MO',\n",
       "       'Rockville, MD', 'Carpinteria, CA', 'Columbia, SC',\n",
       "       'Hauppauge, NY', 'Fort Meade, MD', 'Columbia, MO', 'Vicksburg, MS',\n",
       "       'Birmingham, AL', 'Blue Bell, PA', 'Cincinnati, OH',\n",
       "       'Harrisburg, PA', 'Oak Ridge, TN', 'San Carlos, CA', 'Waltham, MA',\n",
       "       'Fort Worth, TX', 'Smithfield, RI', 'Cedar Rapids, IA',\n",
       "       'Fort Belvoir, VA', 'Linthicum Heights, MD', 'Maple Plain, MN',\n",
       "       'Tulsa, OK', 'Baltimore, MD', 'Oklahoma City, OK',\n",
       "       'Scotts Valley, CA', 'Spartanburg, SC', 'Hartford, CT',\n",
       "       'Beavercreek, OH', 'Norfolk, VA', 'Charlotte, NC', 'Champaign, IL',\n",
       "       'Texas', 'Hoboken, NJ', 'Lebanon, IN', 'Oakland, CA',\n",
       "       'Melbourne, FL', 'Cleveland, OH', 'Norwell, MA', 'San Jose, CA',\n",
       "       'Piscataway, NJ', 'Danvers, MA', 'Vienna, VA', 'Livermore, CA',\n",
       "       'Pittsburgh, PA', 'Irvine, CA', 'Oshkosh, WI', 'Menlo Park, CA',\n",
       "       'Dallas, TX', 'Arlington, VA', 'Monroe, WI', 'Sacramento, CA',\n",
       "       'Hampton, VA', 'Richmond, VA', 'Monterey, CA', 'Woodlawn, MD',\n",
       "       'Ann Arbor, MI', 'Concord, CA', 'Durham, NC', 'Kent, OH',\n",
       "       'Laurel, MD', 'Columbia, MD', 'Falls Church, VA',\n",
       "       'Thousand Oaks, CA', 'Edison, NJ', 'Adelphi, MD', 'Seattle, WA',\n",
       "       'Sunnyvale, CA', 'Fremont, CA', 'Hamilton, NJ', 'Huntsville, AL',\n",
       "       'Merrifield, VA', 'Madison, WI', 'Philadelphia, PA',\n",
       "       'Winston-Salem, NC', 'Raleigh, NC', 'Burbank, CA', 'San Ramon, CA',\n",
       "       'Oxnard, CA', 'Kansas City, MO', 'Jersey City, NJ',\n",
       "       'Manchester, NH', 'Winters, TX', 'Brooklyn, NY', 'Germantown, MD',\n",
       "       'Omaha, NE', 'Open Fork, VA', 'Ashburn, VA', 'Lombard, IL',\n",
       "       'Alpharetta, GA', 'Boulder, CO', 'Mountain View, CA',\n",
       "       'Trumbull, CT', 'Sterling, VA', 'Foster City, CA', 'Frederick, MD',\n",
       "       'Colorado Springs, CO', 'Southfield, MI', 'San Clemente, CA',\n",
       "       'The Woodlands, TX', 'Pleasanton, CA', 'Wilmington, DE',\n",
       "       'Fort Sam Houston, TX', 'Lexington Park, MD',\n",
       "       'Patuxent, Anne Arundel, MD', 'Fairfax, VA', 'San Antonio, TX',\n",
       "       'Silver Spring, MD', 'Portland, OR', 'Simi Valley, CA',\n",
       "       'New Bedford, MA', 'Rancho Cucamonga, CA', 'Collegeville, PA',\n",
       "       'Minneapolis, MN', 'Gahanna, OH', 'California', 'Wellesley, MA',\n",
       "       'Washington, VA', 'Orange, CA', 'Bridgeport, WV', 'Oakville, CA',\n",
       "       'Naperville, IL', 'Houston, TX', 'Redmond, WA', 'West Chester, PA',\n",
       "       'Quantico, VA', 'Fort Lee, NJ', 'Irwindale, CA'], dtype=object)"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df['Location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_location_new_feature(value):\n",
    "    \"\"\"\n",
    "    Cleans the input string by removing the newline character ('\\n') and any text that follows it.\n",
    "\n",
    "    Parameters:\n",
    "    --------------\n",
    "    value (str): \n",
    "        A string containing company names and additional information after a newline character.\n",
    "\n",
    "    Returns:\n",
    "    --------------\n",
    "    str: \n",
    "        A cleaned version of the input string with the part after the newline removed.\n",
    "    \"\"\"\n",
    "    state_and_abr =  value.split(', ')\n",
    "    if len(state_and_abr) > 1:\n",
    "        if len(state_and_abr) == 2: \n",
    "            return state_and_abr[1]\n",
    "        else:\n",
    "            return value[:2].upper()\n",
    "    else:\n",
    "        return value[:2].upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_df['job_location'] = cleaning_df['Location'].apply(job_location_new_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NY', 'VA', 'MA', 'CA', 'IL', 'MO', 'WA', 'DC', 'RE', 'TN', 'TX',\n",
       "       'PA', 'AZ', 'WI', 'GA', 'FL', 'UN', 'NE', 'KS', 'NH', 'NJ', 'LA',\n",
       "       'OH', 'IN', 'MD', 'CO', 'UT', 'OR', 'MI', 'SC', 'MS', 'AL', 'RI',\n",
       "       'IA', 'MN', 'OK', 'CT', 'NC', 'TE', 'DE', 'WV'], dtype=object)"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df['job_location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_location_faeture(value):\n",
    "    \"\"\"\n",
    "    Extracts the state abbreviation from a given location string. If the location contains a comma, it assumes \n",
    "    the format is 'City, State' and returns the state abbreviation. If the location does not contain a comma,\n",
    "    it returns the first two characters of the string as the state abbreviation (in uppercase).\n",
    "\n",
    "    Parameters:\n",
    "    -------------\n",
    "    value (str): \n",
    "        A location string, either in the format 'City, State' or a plain state name.\n",
    "\n",
    "    Returns:\n",
    "    -------------\n",
    "    str: \n",
    "        The state abbreviation in uppercase. If the input is a city with a state, the state abbreviation\n",
    "        is returned. If the input is a state, the first two letters of the state are returned.\n",
    "    \"\"\"\n",
    "    state_and_abr = value.split(', ')\n",
    "    return state_and_abr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_df['Location'] = cleaning_df['Location'].apply(clean_location_faeture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['New York', 'Chantilly', 'Boston', 'Newton', 'Santa Barbara',\n",
       "       'Cambridge', 'Bedford', 'San Diego', 'Chicago', 'Herndon',\n",
       "       'Saint Louis', 'Richland', 'Northbrook', 'Washington', 'Remote',\n",
       "       'Memphis', 'Plano', 'West Grove', 'Phoenix', 'Appleton', 'Atlanta',\n",
       "       'Orlando', 'Lexington', 'McLean', 'San Francisco', 'Sheboygan',\n",
       "       'United States', 'Bothell', 'Lincoln', 'Overland Park',\n",
       "       'Santa Monica', 'Portsmouth', 'Ewing', 'South San Francisco',\n",
       "       'Palo Alto', 'Bellevue', 'New Orleans', 'Akron', 'Fort Wayne',\n",
       "       'Woburn', 'Carson', 'Coral Gables', 'Santa Clara', 'Brisbane',\n",
       "       'Winter Park', 'Redwood City', 'Peoria', 'Ipswich', 'Carmel',\n",
       "       'Emeryville', 'Gaithersburg', 'Longmont', 'Austin', 'Yakima',\n",
       "       'Santa Cruz', 'Springfield', 'Alexandria', 'Utah', 'Reston',\n",
       "       'Denver', 'New Jersey', 'Aurora', 'Hill AFB', 'Chandler',\n",
       "       'Indianapolis', 'Nashville', 'Timonium', 'Burlingame',\n",
       "       'Annapolis Junction', 'Bethesda', 'Dayton', 'Schaumburg',\n",
       "       'Cupertino', 'Lehi', 'Culver City', 'Lake Oswego', 'San Mateo',\n",
       "       'Holyoke', 'Woodbridge', 'Dearborn', 'Maryland Heights',\n",
       "       'Rockville', 'Carpinteria', 'Columbia', 'Hauppauge', 'Fort Meade',\n",
       "       'Vicksburg', 'Birmingham', 'Blue Bell', 'Cincinnati', 'Harrisburg',\n",
       "       'Oak Ridge', 'San Carlos', 'Waltham', 'Fort Worth', 'Smithfield',\n",
       "       'Cedar Rapids', 'Fort Belvoir', 'Linthicum Heights', 'Maple Plain',\n",
       "       'Tulsa', 'Baltimore', 'Oklahoma City', 'Scotts Valley',\n",
       "       'Spartanburg', 'Hartford', 'Beavercreek', 'Norfolk', 'Charlotte',\n",
       "       'Champaign', 'Texas', 'Hoboken', 'Lebanon', 'Oakland', 'Melbourne',\n",
       "       'Cleveland', 'Norwell', 'San Jose', 'Piscataway', 'Danvers',\n",
       "       'Vienna', 'Livermore', 'Pittsburgh', 'Irvine', 'Oshkosh',\n",
       "       'Menlo Park', 'Dallas', 'Arlington', 'Monroe', 'Sacramento',\n",
       "       'Hampton', 'Richmond', 'Monterey', 'Woodlawn', 'Ann Arbor',\n",
       "       'Concord', 'Durham', 'Kent', 'Laurel', 'Falls Church',\n",
       "       'Thousand Oaks', 'Edison', 'Adelphi', 'Seattle', 'Sunnyvale',\n",
       "       'Fremont', 'Hamilton', 'Huntsville', 'Merrifield', 'Madison',\n",
       "       'Philadelphia', 'Winston-Salem', 'Raleigh', 'Burbank', 'San Ramon',\n",
       "       'Oxnard', 'Kansas City', 'Jersey City', 'Manchester', 'Winters',\n",
       "       'Brooklyn', 'Germantown', 'Omaha', 'Open Fork', 'Ashburn',\n",
       "       'Lombard', 'Alpharetta', 'Boulder', 'Mountain View', 'Trumbull',\n",
       "       'Sterling', 'Foster City', 'Frederick', 'Colorado Springs',\n",
       "       'Southfield', 'San Clemente', 'The Woodlands', 'Pleasanton',\n",
       "       'Wilmington', 'Fort Sam Houston', 'Lexington Park', 'Patuxent',\n",
       "       'Fairfax', 'San Antonio', 'Silver Spring', 'Portland',\n",
       "       'Simi Valley', 'New Bedford', 'Rancho Cucamonga', 'Collegeville',\n",
       "       'Minneapolis', 'Gahanna', 'California', 'Wellesley', 'Orange',\n",
       "       'Bridgeport', 'Oakville', 'Naperville', 'Houston', 'Redmond',\n",
       "       'West Chester', 'Quantico', 'Fort Lee', 'Irwindale'], dtype=object)"
      ]
     },
     "execution_count": 676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df['Location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Job Title', 'Salary Estimate', 'Job Description', 'Rating',\n",
       "       'Company Name', 'Location', 'Headquarters', 'Size', 'Founded',\n",
       "       'Type of ownership', 'Industry', 'Sector', 'Revenue', 'Competitors',\n",
       "       'job_location'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Headquarters Feature`\n",
    "\n",
    "The Headquarters feature contains the location of company headquarters, represented as city and state (or country) pairs, with values such as \"New York, NY,\" \"Herndon, VA,\" and \"Santa Barbara, CA.\" After analyzing the data, it was decided that no modifications or cleaning were necessary for this feature, as the values are already in a standardized format. Therefore, the Headquarters column remains unchanged and is retained as it is for further analysis or processing within the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['New York, NY', 'Herndon, VA', 'Boston, MA',\n",
       "       'Bad Ragaz, Switzerland', 'Santa Barbara, CA',\n",
       "       'Basel, Switzerland', 'Bedford, MA', 'Mountain View, CA',\n",
       "       'Chicago, IL', 'Mc Lean, VA', 'Saint Louis, MO', 'Richland, WA',\n",
       "       'Northbrook, IL', 'Princeton, NJ', 'Mays Landing, NJ',\n",
       "       'Washington, DC', 'Memphis, TN', 'Tempe, AZ', 'Reading, PA',\n",
       "       'San Francisco, CA', 'Menlo Park, CA', 'Atlanta, GA',\n",
       "       'Orlando, FL', 'Lexington, MA', 'Falls Church, VA',\n",
       "       'Sheboygan, WI', 'Seattle, WA', 'Bellevue, WA', 'Lincoln, NE',\n",
       "       'Chantilly, VA', 'Santa Monica, CA', 'Ewing, NJ',\n",
       "       'South San Francisco, CA', 'Palo Alto, CA', 'Singapore, Singapore',\n",
       "       'Cambridge, MA', 'OSAKA, Japan', 'Santa Clara, CA', 'Vienna, VA',\n",
       "       'New Orleans, LA', 'Akron, OH', 'Zurich, Switzerland',\n",
       "       'Woburn, MA', 'Carson, CA', 'Coral Gables, FL', 'San Ramon, CA',\n",
       "       'Brisbane, CA', 'Winter Park, FL', 'San Rafael, CA',\n",
       "       'Deerfield, IL', 'Ipswich, MA', 'Carmel, IN', 'Chevy Chase, MD',\n",
       "       'Hartford, CT', 'Emeryville, CA', 'Cambridge, United Kingdom',\n",
       "       'Rockville, MD', 'Minneapolis, MN', 'Austin, TX', 'Yakima, WA',\n",
       "       'Santa Cruz, CA', 'South Jordan, UT', 'Reston, VA', 'Denver, CO',\n",
       "       'Holmdel, NJ', 'Aurora, CO', 'San Mateo, CA', 'Goleta, CA',\n",
       "       'Franklin, TN', 'Indianapolis, IN', 'Lutherville Timonium, MD',\n",
       "       'Westminster, CO', 'Burlingame, CA', 'Annapolis Junction, MD',\n",
       "       'Bethesda, MD', 'Beavercreek, OH', 'Schaumburg, IL',\n",
       "       'Sunnyvale, CA', 'Lehi, UT', 'Lake Oswego, OR', 'Holyoke, MA',\n",
       "       'Dulles, VA', 'San Diego, CA', 'Detroit, MI', 'Stamford, CT',\n",
       "       'Carpinteria, CA', 'Columbia, SC', '-1', \"Marcy-l'Etoile, France\",\n",
       "       'Columbia, MO', 'Fairfax, VA', 'Chandler, AZ', 'Aurora, Canada',\n",
       "       'Blue Bell, PA', 'Troy, MI', 'Redwood City, CA', 'Greenville, SC',\n",
       "       'Arlington, VA', 'Harrisburg, PA', 'Hamilton, Bermuda',\n",
       "       'Lynchburg, VA', 'Springfield, MA', 'San Carlos, CA',\n",
       "       'Waltham, MA', 'San Jose, CA', 'Jersey City, NJ', 'Fort Worth, TX',\n",
       "       'Cedar Rapids, IA', 'McLean, VA', 'Lorton, VA', 'Maple Plain, MN',\n",
       "       'Kent, WA', 'Woodbine, MD', 'San Antonio, TX', 'Scotts Valley, CA',\n",
       "       'Spartanburg, SC', 'Woodbridge, NJ', 'Chennai, India',\n",
       "       'Tel Aviv-Yafo, Israel', 'Baltimore, MD', 'Manalapan, NJ',\n",
       "       'Charlotte, NC', 'Saxonburg, PA', 'Bristol, PA',\n",
       "       'Bangalore, India', 'Hoboken, NJ', 'Paris, France',\n",
       "       'Greenwich, CT', 'Santa Ana, CA', 'Houston, TX', 'Tucson, AZ',\n",
       "       'Birmingham, AL', 'Cleveland, OH', 'Pleasanton, CA',\n",
       "       'Columbus, OH', 'Piscataway, NJ', 'Danvers, MA',\n",
       "       'Philadelphia, PA', 'Livermore, CA', 'Pittsburgh, PA',\n",
       "       'Dallas, TX', 'Toronto, Canada', 'Irvine, CA', 'Hillsborough, NJ',\n",
       "       'Oshkosh, WI', 'Fremont, CA', 'Monroe, WI', 'Goteborg, Sweden',\n",
       "       'Lake Buena Vista, FL', 'Schaffhausen, Switzerland',\n",
       "       'Richmond, VA', 'Newark, CA', 'Greensboro, NC', 'Scottsdale, AZ',\n",
       "       'Irving, TX', 'Beltsville, MD', 'Naperville, IL',\n",
       "       'Brentford, United Kingdom', 'Cincinnati, OH', 'Somerset, NJ',\n",
       "       'London, United Kingdom', 'Raleigh, NC', 'Leesburg, VA',\n",
       "       'Durham, NC', 'Kent, OH', 'Westlake Village, CA',\n",
       "       'North Brunswick, NJ', 'Benicia, CA', 'Laurel, MD', 'Columbia, MD',\n",
       "       'Danville, CA', 'Wilmington, MA', 'New York, 061', 'Reading, MA',\n",
       "       'Folsom, CA', 'Wilsonville, OR', 'Huntsville, AL', 'Madison, WI',\n",
       "       'Phila, PA', 'Winston-Salem, NC', 'Half Moon Bay, CA',\n",
       "       'Los Angeles, CA', 'Hilliard, OH', 'Hanover, MD',\n",
       "       'Kansas City, MO', 'Bengaluru, India', 'Alpharetta, GA',\n",
       "       'Germantown, MD', 'Omaha, NE', 'Clifton Park, NY', 'Livonia, MI',\n",
       "       'Ashburn, VA', 'Nashville, TN', 'Alexandria, VA', 'Edison, NJ',\n",
       "       'Ventura, CA', 'Armonk, NY', 'Trumbull, CT', 'Chadds Ford, PA',\n",
       "       'Saint Paul, MN', 'Glen Allen, VA', 'Aliso Viejo, CA',\n",
       "       'Plainsboro, NJ', 'Fairmont, WV', 'Cherry Hill, NJ', 'Itasca, IL',\n",
       "       'Coconut Creek, FL', 'Lombard, IL', 'Honolulu, HI',\n",
       "       'Carle Place, NY', 'Cupertino, CA', 'Tampa, FL', 'Totowa, NJ',\n",
       "       'Rome, NY', 'Milan, IL', 'Marbella, Spain', 'Simi Valley, CA',\n",
       "       'Rancho Cucamonga, CA', 'Albuquerque, NM', 'Langley, VA',\n",
       "       'Plano, TX', 'Albertville, AL', 'Orange, CA', 'Littleton, CO',\n",
       "       'Oakville, Canada', 'San Bruno, CA', 'West Chester, PA',\n",
       "       'Utica, MI', 'Fort Lee, NJ'], dtype=object)"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df['Headquarters'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Size Feature`\n",
    "\n",
    "The Size feature in the dataset represents the number of employees in a company, with values like '1001 to 5000 employees', '5001 to 10000 employees', and 'Unknown'. To standardize these values, the function convert_size_feature was applied to convert the employee size descriptions into a unified range format, such as '1001-5000', '5001-10000', and '10000+' for companies with more than 10,000 employees. Values like '-1' or 'Unknown' were preserved as 'Unknown'. Finally, the column was renamed to company_employees to better reflect its content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1001 to 5000 employees', '5001 to 10000 employees',\n",
       "       '501 to 1000 employees', '51 to 200 employees', '10000+ employees',\n",
       "       '201 to 500 employees', '1 to 50 employees', '-1', 'Unknown'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df['Size'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_size_feature(value):\n",
    "    \"\"\"\n",
    "    Converts employee size descriptions into a standardized range.\n",
    "\n",
    "    If the value is '-1' or 'Unknown', it returns 'Unknown'.\n",
    "    For other values, it extracts the employee range from the description and returns it in a \n",
    "    standardized format.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    value (str): \n",
    "        A string describing the size of the company in terms of employee count, such as\n",
    "        '1001 to 5000 employees' or '5001 to 10000 employees'.\n",
    "\n",
    "    Returns:\n",
    "    ------------\n",
    "    str: \n",
    "        A standardized employee range, such as '1001-5000'. If the value is '-1' or 'Unknown',\n",
    "        it returns 'Unknown'.\n",
    "\n",
    "    \"\"\"\n",
    "    if value in ['-1', 'Unknown']:\n",
    "        return 'Unknown'\n",
    "    if '10000+' in value:\n",
    "        return '10000+'\n",
    "    match = re.search(r'(\\d+)(?: to )(\\d+)', value)\n",
    "    return f'{match.group(1)}-{match.group(2)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_df['Size'] = cleaning_df['Size'].apply(convert_size_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1001-5000', '5001-10000', '501-1000', '51-200', '10000+',\n",
       "       '201-500', '1-50', 'Unknown'], dtype=object)"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df['Size'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_df = cleaning_df.rename(columns={'Size': 'company_employees'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Estimate</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Headquarters</th>\n",
       "      <th>company_employees</th>\n",
       "      <th>Founded</th>\n",
       "      <th>Type of ownership</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Competitors</th>\n",
       "      <th>job_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>137-171</td>\n",
       "      <td>Description\\n\\nThe Senior Data Scientist is re...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Healthfirst</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1001-5000</td>\n",
       "      <td>1993</td>\n",
       "      <td>Nonprofit Organization</td>\n",
       "      <td>Insurance Carriers</td>\n",
       "      <td>Insurance</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>EmblemHealth, UnitedHealth Group, Aetna</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Job Title Salary Estimate  \\\n",
       "0  Sr Data Scientist         137-171   \n",
       "\n",
       "                                     Job Description  Rating Company Name  \\\n",
       "0  Description\\n\\nThe Senior Data Scientist is re...     3.1  Healthfirst   \n",
       "\n",
       "   Location  Headquarters company_employees  Founded       Type of ownership  \\\n",
       "0  New York  New York, NY         1001-5000     1993  Nonprofit Organization   \n",
       "\n",
       "             Industry     Sector                   Revenue  \\\n",
       "0  Insurance Carriers  Insurance  Unknown / Non-Applicable   \n",
       "\n",
       "                               Competitors job_location  \n",
       "0  EmblemHealth, UnitedHealth Group, Aetna           NY  "
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Founded Feature`\n",
    "\n",
    "The Founded feature represents the year a company was established, but it contains a significant number of missing values, with 118 entries marked as -1. Given that this column has many missing or invalid entries, and considering it may not be crucial for the analysis, the decision was made to drop this column from the dataset. This will help streamline the data and avoid any potential noise caused by the incomplete information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1993, 1968, 1981, 2000, 1998, 2010, 1996, 1990, 1983, 2014, 2012,\n",
       "       2016, 1965, 1973, 1986, 1997, 2015, 1945, 1988, 2017, 2011, 1967,\n",
       "       1860, 1992, 2003, 1951, 2005, 2019, 1925, 2008, 1999, 1978, 1966,\n",
       "       1912, 1958, 2013, 1849, 1781, 1926, 2006, 1994, 1863, 1995,   -1,\n",
       "       1982, 1974, 2001, 1985, 1913, 1971, 1911, 2009, 1959, 2007, 1939,\n",
       "       2002, 1961, 1963, 1969, 1946, 1957, 1953, 1948, 1850, 1851, 2004,\n",
       "       1976, 1918, 1954, 1947, 1955, 2018, 1937, 1917, 1935, 1929, 1820,\n",
       "       1952, 1932, 1894, 1960, 1788, 1830, 1984, 1933, 1880, 1887, 1970,\n",
       "       1942, 1980, 1989, 1908, 1853, 1875, 1914, 1898, 1956, 1977, 1987,\n",
       "       1896, 1972, 1949, 1962], dtype=int64)"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df['Founded'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaning_df[cleaning_df['Founded'] == -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_df = cleaning_df.drop(labels='Founded', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Estimate</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Headquarters</th>\n",
       "      <th>company_employees</th>\n",
       "      <th>Type of ownership</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Competitors</th>\n",
       "      <th>job_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>137-171</td>\n",
       "      <td>Description\\n\\nThe Senior Data Scientist is re...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Healthfirst</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1001-5000</td>\n",
       "      <td>Nonprofit Organization</td>\n",
       "      <td>Insurance Carriers</td>\n",
       "      <td>Insurance</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>EmblemHealth, UnitedHealth Group, Aetna</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Job Title Salary Estimate  \\\n",
       "0  Sr Data Scientist         137-171   \n",
       "\n",
       "                                     Job Description  Rating Company Name  \\\n",
       "0  Description\\n\\nThe Senior Data Scientist is re...     3.1  Healthfirst   \n",
       "\n",
       "   Location  Headquarters company_employees       Type of ownership  \\\n",
       "0  New York  New York, NY         1001-5000  Nonprofit Organization   \n",
       "\n",
       "             Industry     Sector                   Revenue  \\\n",
       "0  Insurance Carriers  Insurance  Unknown / Non-Applicable   \n",
       "\n",
       "                               Competitors job_location  \n",
       "0  EmblemHealth, UnitedHealth Group, Aetna           NY  "
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Type of ownership Feature`\n",
    "\n",
    "The Type of ownership feature categorizes companies based on their ownership structure. However, the dataset contains missing or unknown values, represented as -1 and Unknown. To standardize this feature, all -1 values have been converted to 'Unknown'. This ensures consistency in the dataset while preserving relevant ownership classifications such as 'Company - Public', 'Company - Private', 'Government', and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Nonprofit Organization', 'Company - Public',\n",
       "       'Private Practice / Firm', 'Company - Private', 'Government',\n",
       "       'Subsidiary or Business Segment', 'Other Organization', '-1',\n",
       "       'Unknown', 'Hospital', 'Self-employed', 'College / University',\n",
       "       'Contract'], dtype=object)"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df['Type of ownership'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_type_of_ownership_feature(value):\n",
    "    \"\"\"\n",
    "    Cleans the 'Type of Ownership' feature by replacing '-1' with 'Unknown'.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    value (str): \n",
    "        A string representing the type of ownership.\n",
    "\n",
    "    Returns:\n",
    "    ------------\n",
    "    str: \n",
    "        'Unknown' if the input is '-1', otherwise returns the original value.\n",
    "    \"\"\"\n",
    "    if value == '-1':\n",
    "        return 'Unknown'\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_df['Type of ownership'] = cleaning_df['Type of ownership'].apply(clean_type_of_ownership_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Nonprofit Organization', 'Company - Public',\n",
       "       'Private Practice / Firm', 'Company - Private', 'Government',\n",
       "       'Subsidiary or Business Segment', 'Other Organization', 'Unknown',\n",
       "       'Hospital', 'Self-employed', 'College / University', 'Contract'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df['Type of ownership'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Job Title', 'Salary Estimate', 'Job Description', 'Rating',\n",
       "       'Company Name', 'Location', 'Headquarters', 'company_employees',\n",
       "       'Type of ownership', 'Industry', 'Sector', 'Revenue', 'Competitors',\n",
       "       'job_location'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Industry Feature`\n",
    "\n",
    "The Industry feature classifies companies based on their sector of operation. However, some entries in the dataset are missing or labeled as -1. To maintain data consistency, all -1 values have been converted to 'Unknown'. This ensures that the dataset remains structured while retaining valuable industry classifications such as 'Insurance Carriers', 'Biotech & Pharmaceuticals', 'IT Services', and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Insurance Carriers', 'Research & Development', 'Consulting',\n",
       "       'Electrical & Electronic Manufacturing', 'Advertising & Marketing',\n",
       "       'Computer Hardware & Software', 'Biotech & Pharmaceuticals',\n",
       "       'Consumer Electronics & Appliances Stores',\n",
       "       'Enterprise Software & Network Solutions', 'IT Services', 'Energy',\n",
       "       'Chemical Manufacturing', 'Federal Agencies', 'Internet',\n",
       "       'Health Care Services & Hospitals',\n",
       "       'Investment Banking & Asset Management', 'Aerospace & Defense',\n",
       "       'Utilities', '-1', 'Express Delivery Services',\n",
       "       'Staffing & Outsourcing', 'Insurance Agencies & Brokerages',\n",
       "       'Consumer Products Manufacturing', 'Industrial Manufacturing',\n",
       "       'Food & Beverage Manufacturing', 'Banks & Credit Unions',\n",
       "       'Video Games', 'Shipping', 'Telecommunications Services',\n",
       "       'Lending', 'Cable, Internet & Telephone Providers', 'Real Estate',\n",
       "       'Venture Capital & Private Equity', 'Miscellaneous Manufacturing',\n",
       "       'Oil & Gas Services', 'Transportation Equipment Manufacturing',\n",
       "       'Telecommunications Manufacturing', 'Transportation Management',\n",
       "       'News Outlet', 'Architectural & Engineering Services',\n",
       "       'Food & Beverage Stores', 'Other Retail Stores',\n",
       "       'Hotels, Motels, & Resorts', 'State & Regional Agencies',\n",
       "       'Financial Transaction Processing', 'Timber Operations',\n",
       "       'Colleges & Universities', 'Travel Agencies', 'Accounting',\n",
       "       'Logistics & Supply Chain', 'Farm Support Services',\n",
       "       'Social Assistance', 'Construction',\n",
       "       'Department, Clothing, & Shoe Stores', 'Publishing',\n",
       "       'Health, Beauty, & Fitness', 'Wholesale', 'Rail'], dtype=object)"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df['Industry'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_industry_feature(value):\n",
    "    \"\"\"\n",
    "    Cleans the 'Industry' feature by replacing '-1' with 'Unknown'.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    value (str): \n",
    "        A string representing the industry.\n",
    "\n",
    "    Returns:\n",
    "    ------------\n",
    "    str: \n",
    "        'Unknown' if the input is '-1', otherwise returns the original value.\n",
    "    \"\"\"\n",
    "    if value == '-1':\n",
    "        return 'Unknown'\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_df['Industry'] = cleaning_df['Industry'].apply(clean_industry_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Insurance Carriers', 'Research & Development', 'Consulting',\n",
       "       'Electrical & Electronic Manufacturing', 'Advertising & Marketing',\n",
       "       'Computer Hardware & Software', 'Biotech & Pharmaceuticals',\n",
       "       'Consumer Electronics & Appliances Stores',\n",
       "       'Enterprise Software & Network Solutions', 'IT Services', 'Energy',\n",
       "       'Chemical Manufacturing', 'Federal Agencies', 'Internet',\n",
       "       'Health Care Services & Hospitals',\n",
       "       'Investment Banking & Asset Management', 'Aerospace & Defense',\n",
       "       'Utilities', 'Unknown', 'Express Delivery Services',\n",
       "       'Staffing & Outsourcing', 'Insurance Agencies & Brokerages',\n",
       "       'Consumer Products Manufacturing', 'Industrial Manufacturing',\n",
       "       'Food & Beverage Manufacturing', 'Banks & Credit Unions',\n",
       "       'Video Games', 'Shipping', 'Telecommunications Services',\n",
       "       'Lending', 'Cable, Internet & Telephone Providers', 'Real Estate',\n",
       "       'Venture Capital & Private Equity', 'Miscellaneous Manufacturing',\n",
       "       'Oil & Gas Services', 'Transportation Equipment Manufacturing',\n",
       "       'Telecommunications Manufacturing', 'Transportation Management',\n",
       "       'News Outlet', 'Architectural & Engineering Services',\n",
       "       'Food & Beverage Stores', 'Other Retail Stores',\n",
       "       'Hotels, Motels, & Resorts', 'State & Regional Agencies',\n",
       "       'Financial Transaction Processing', 'Timber Operations',\n",
       "       'Colleges & Universities', 'Travel Agencies', 'Accounting',\n",
       "       'Logistics & Supply Chain', 'Farm Support Services',\n",
       "       'Social Assistance', 'Construction',\n",
       "       'Department, Clothing, & Shoe Stores', 'Publishing',\n",
       "       'Health, Beauty, & Fitness', 'Wholesale', 'Rail'], dtype=object)"
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df['Industry'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Sector Feature`\n",
    "\n",
    "The Sector feature categorizes companies into broader industries, such as 'Information Technology', 'Health Care', and 'Finance'. Since some entries in the dataset were labeled as -1, these have been replaced with 'Unknown' to ensure data consistency. This transformation helps maintain a structured dataset while preserving meaningful sector classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Insurance', 'Business Services', 'Manufacturing',\n",
       "       'Information Technology', 'Biotech & Pharmaceuticals', 'Retail',\n",
       "       'Oil, Gas, Energy & Utilities', 'Government', 'Health Care',\n",
       "       'Finance', 'Aerospace & Defense', '-1',\n",
       "       'Transportation & Logistics', 'Media', 'Telecommunications',\n",
       "       'Real Estate', 'Travel & Tourism', 'Agriculture & Forestry',\n",
       "       'Education', 'Accounting & Legal', 'Non-Profit',\n",
       "       'Construction, Repair & Maintenance', 'Consumer Services'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df['Sector'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sector_feature(value):\n",
    "    \"\"\"\n",
    "    Cleans the 'Sector' feature by replacing '-1' with 'Unknown'.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    value (str): \n",
    "        A string representing the industry.\n",
    "\n",
    "    Returns:\n",
    "    ------------\n",
    "    str: \n",
    "        'Unknown' if the input is '-1', otherwise returns the original value.\n",
    "    \"\"\"\n",
    "    if value == '-1':\n",
    "        return 'Unknown'\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_df['Sector'] = cleaning_df['Sector'].apply(clean_sector_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Revenue Feature`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unknown / Non-Applicable', '$1 to $2 billion (USD)',\n",
       "       '$100 to $500 million (USD)', '$10+ billion (USD)',\n",
       "       '$2 to $5 billion (USD)', '$500 million to $1 billion (USD)',\n",
       "       '$5 to $10 billion (USD)', '$10 to $25 million (USD)',\n",
       "       '$25 to $50 million (USD)', '$50 to $100 million (USD)',\n",
       "       '$1 to $5 million (USD)', '$5 to $10 million (USD)',\n",
       "       'Less than $1 million (USD)', '-1'], dtype=object)"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df['Revenue'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_revenue_feature(value):\n",
    "    \"\"\"\n",
    "    Cleans the 'Revenue' feature by replacing '-1' with 'Unknown / Non-Applicable'.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    value (str): \n",
    "        A string representing the industry.\n",
    "\n",
    "    Returns:\n",
    "    ------------\n",
    "    str: \n",
    "        'Unknown' if the input is '-1', otherwise returns the original value.\n",
    "    \"\"\"\n",
    "    if value == '-1':\n",
    "        return 'Unknown / Non-Applicable'\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_df['Revenue'] = cleaning_df['Revenue'].apply(clean_revenue_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unknown / Non-Applicable', '$1 to $2 billion (USD)',\n",
       "       '$100 to $500 million (USD)', '$10+ billion (USD)',\n",
       "       '$2 to $5 billion (USD)', '$500 million to $1 billion (USD)',\n",
       "       '$5 to $10 billion (USD)', '$10 to $25 million (USD)',\n",
       "       '$25 to $50 million (USD)', '$50 to $100 million (USD)',\n",
       "       '$1 to $5 million (USD)', '$5 to $10 million (USD)',\n",
       "       'Less than $1 million (USD)'], dtype=object)"
      ]
     },
     "execution_count": 704,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df['Revenue'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Job Title', 'Salary Estimate', 'Job Description', 'Rating',\n",
       "       'Company Name', 'Location', 'Headquarters', 'company_employees',\n",
       "       'Type of ownership', 'Industry', 'Sector', 'Revenue', 'Competitors',\n",
       "       'job_location'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Competitors Feature`\n",
    "\n",
    "The Competitors feature was dropped because it contained a large number of missing values (501 entries labeled as -1). Given its limited usefulness for analysis and the high percentage of missing data, removing the column helps streamline the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EmblemHealth, UnitedHealth Group, Aetna', '-1',\n",
       "       'MKS Instruments, Pfeiffer Vacuum, Agilent Technologies',\n",
       "       'Commerce Signals, Cardlytics, Yodlee',\n",
       "       'Square, PayPal, H&R Block',\n",
       "       'Leidos, CACI International, Booz Allen Hamilton',\n",
       "       'Slalom, Daugherty Business Solutions',\n",
       "       'Oak Ridge National Laboratory, National Renewable Energy Lab, Los Alamos National Laboratory',\n",
       "       'CDW, PCM, SHI International',\n",
       "       'Crossix Solutions Inc., AppNexus, The Trade Desk',\n",
       "       'Northwestern Mutual', 'Puppet, Ansible, SaltStack',\n",
       "       'Enlivant, Sunrise Senior Living, Brookdale Senior Living',\n",
       "       'TrueCar, Cars.com, Kelley Blue Book',\n",
       "       'Travelers, Allstate, State Farm', 'Novartis, Baxter, Pfizer',\n",
       "       'Skyhigh Networks, Zscaler, NortonLifeLock',\n",
       "       'Facebook, Google, Pinterest', 'DoorDash, Uber, Grubhub',\n",
       "       'Munich Re, Hannover RE, SCOR', \"IMAGE Skincare, Aveda, Kiehl's\",\n",
       "       'Luxoft, EPAM, Capgemini Invent', 'Sequenom',\n",
       "       'Linqia, Collective Bias', 'John Deere, Komatsu, CNH Industrial',\n",
       "       'Thermo Fisher Scientific, Enzymatics, Illumina',\n",
       "       'CUNA Mutual, SWBC, Overby-Seawell', 'Zola Registry',\n",
       "       'Colony Specialty, Markel, RLI',\n",
       "       'Roche, GlaxoSmithKline, Novartis',\n",
       "       'Solution Design Group, Intertech (Minnesota)',\n",
       "       'Braintree, Authorize.Net, PayPal', 'Nielsen, Zappi, SurveyMonkey',\n",
       "       'The World Bank, IMF', 'Booz Allen Hamilton, CACI International',\n",
       "       'Booz Allen Hamilton, SAIC, LMI', 'Epic, CipherHealth',\n",
       "       'Copper River Shared Services, Chenega Corporation, Deloitte',\n",
       "       'Battelle, General Atomics, SAIC', 'IQVIA, ICON',\n",
       "       'Arbella Insurance, Safety Insurance',\n",
       "       'Engagio, Bombora, Terminus', 'SAIC, Leidos, Northrop Grumman',\n",
       "       'Bosch, Lear Corporation, Faurecia', 'Covance, ICON',\n",
       "       'Adecco, ManpowerGroup, Allegis Corporation',\n",
       "       'GE Digital, Palantir Technologies, Uptake', 'PRA Group',\n",
       "       'Genomic Health, 23andMe, Illumina',\n",
       "       'Bromium, FireEye, Authentic8', 'Drip, iContact, Mailchimp',\n",
       "       \"Children's Health, Texas Health Resources, Baylor Scott & White Health\",\n",
       "       'Harris, Fibertek', 'Monster Worldwide, CareerBuilder, Craigslist',\n",
       "       'Los Alamos National Laboratory, Battelle, SRI International',\n",
       "       'ManTech, Booz Allen Hamilton, Leidos',\n",
       "       'Lumentum Operations, Keysight Technologies, O-Net Technologies',\n",
       "       'Square, Amazon, Apple', 'Pfizer, GlaxoSmithKline',\n",
       "       'DHL Supply Chain, UPS, FedEx',\n",
       "       'Raytheon Technologies, General Dynamics, MIT Lincoln Laboratory',\n",
       "       'Eaton, SMC Corporation, Bosch Rexroth',\n",
       "       'Advisory Board, Booz Allen Hamilton, McKinsey & Company',\n",
       "       'Amazon, Apple', 'Covidien, Boston Scientific', 'AT&T, Verizon',\n",
       "       'Los Alamos National Laboratory, NASA Jet Propulsion Laboratory, Sandia National Laboratories',\n",
       "       'Fluor, Bechtel, AECOM', 'Intertek, SGS, Bureau Veritas',\n",
       "       'Lockheed Martin, Caterpillar, John Deere',\n",
       "       'Activision Blizzard, Electronic Arts',\n",
       "       'MediaMath, Conversant, AppNexus', 'Pfizer, AstraZeneca, Merck',\n",
       "       'Archibus, iOffice, Planon',\n",
       "       'ACRT Services, Bartlett Tree Experts',\n",
       "       'TASC, Vencore, Booz Allen Hamilton',\n",
       "       'Seagate Technology, Toshiba',\n",
       "       'Raytheon Technologies, Northrop Grumman, Booz Allen Hamilton',\n",
       "       'MIT Lincoln Laboratory, Lockheed Martin, Northrop Grumman',\n",
       "       'Kforce, PageGroup, Robert Half',\n",
       "       'TEKsystems, Kforce, Randstad US',\n",
       "       'South Carolina Electric & Gas, Virginia Electric and Power',\n",
       "       'Cadence Design Systems, Synopsys, Altium Limited',\n",
       "       'CGI (Nevada), Accenture, Deloitte', 'Accenture, Deloitte, PwC',\n",
       "       'Bechtel Jacobs, Black & Veatch, HNTB', 'Adecco, Manpower',\n",
       "       'Acxiom, Merkle, Epsilon (North Carolina)',\n",
       "       'Amazon, Accenture, Microsoft',\n",
       "       'Booz Allen Hamilton, Deloitte, ERPi',\n",
       "       'TEKsystems, Insight Global, Accenture',\n",
       "       'H&M, Inditex, Fast Retailing',\n",
       "       'Novartis, AstraZeneca, Siemens Healthineers',\n",
       "       'Aquent, 24 Seven Talent',\n",
       "       'Google, Microsoft, Samsung Electronics',\n",
       "       'AppDynamics, Datadog, Dynatrace',\n",
       "       'Liberty Mutual Insurance, EMPLOYERS, Travelers',\n",
       "       'KPMG, Accenture, Deloitte',\n",
       "       'General Atomics, Boeing, Northrop Grumman',\n",
       "       'Los Alamos National Laboratory, Lawrence Livermore National Laboratory',\n",
       "       'Cognizant Technology Solutions, Infosys, Wipro', 'Humana',\n",
       "       'Accenture, Northrop Grumman, Xerox',\n",
       "       'United Natural Foods, US Foods, DPI Specialty Foods',\n",
       "       'LivePerson, Salesforce, SAP', 'Zurich Insurance, AXA XL, Allianz',\n",
       "       'CSC, ManTech, SAIC',\n",
       "       'Genomic Health, Myriad Genetics, The Broad Institute'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df['Competitors'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaning_df[cleaning_df['Competitors'] == '-1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_df = cleaning_df.drop(labels='Competitors', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Estimate</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Headquarters</th>\n",
       "      <th>company_employees</th>\n",
       "      <th>Type of ownership</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>job_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>137-171</td>\n",
       "      <td>Description\\n\\nThe Senior Data Scientist is re...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Healthfirst</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1001-5000</td>\n",
       "      <td>Nonprofit Organization</td>\n",
       "      <td>Insurance Carriers</td>\n",
       "      <td>Insurance</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Job Title Salary Estimate  \\\n",
       "0  Sr Data Scientist         137-171   \n",
       "\n",
       "                                     Job Description  Rating Company Name  \\\n",
       "0  Description\\n\\nThe Senior Data Scientist is re...     3.1  Healthfirst   \n",
       "\n",
       "   Location  Headquarters company_employees       Type of ownership  \\\n",
       "0  New York  New York, NY         1001-5000  Nonprofit Organization   \n",
       "\n",
       "             Industry     Sector                   Revenue job_location  \n",
       "0  Insurance Carriers  Insurance  Unknown / Non-Applicable           NY  "
      ]
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Rename Features\n",
    "\n",
    "The feature names were standardized by converting them to lowercase and replacing spaces with underscores. This improves consistency and makes it easier to reference column names in code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cleaning_df = cleaning_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cleaning_df.columns = features_cleaning_df.columns.str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['job_title', 'salary_estimate', 'job_description', 'rating',\n",
       "       'company_name', 'location', 'headquarters', 'company_employees',\n",
       "       'type_of_ownership', 'industry', 'sector', 'revenue', 'job_location'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cleaning_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary_estimate</th>\n",
       "      <th>job_description</th>\n",
       "      <th>rating</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>headquarters</th>\n",
       "      <th>company_employees</th>\n",
       "      <th>type_of_ownership</th>\n",
       "      <th>industry</th>\n",
       "      <th>sector</th>\n",
       "      <th>revenue</th>\n",
       "      <th>job_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>137-171</td>\n",
       "      <td>Description\\n\\nThe Senior Data Scientist is re...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Healthfirst</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1001-5000</td>\n",
       "      <td>Nonprofit Organization</td>\n",
       "      <td>Insurance Carriers</td>\n",
       "      <td>Insurance</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           job_title salary_estimate  \\\n",
       "0  Sr Data Scientist         137-171   \n",
       "\n",
       "                                     job_description  rating company_name  \\\n",
       "0  Description\\n\\nThe Senior Data Scientist is re...     3.1  Healthfirst   \n",
       "\n",
       "   location  headquarters company_employees       type_of_ownership  \\\n",
       "0  New York  New York, NY         1001-5000  Nonprofit Organization   \n",
       "\n",
       "             industry     sector                   revenue job_location  \n",
       "0  Insurance Carriers  Insurance  Unknown / Non-Applicable           NY  "
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cleaning_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Min Salary and Max Salary\n",
    "\n",
    "The salary_estimate column was successfully split into min_salary and max_salary, providing clearer salary range insights. These two new columns allow for more granular salary analysis, such as calculating salary averages or filtering jobs by salary range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['137-171', '75-131', '79-131', '99-132', '90-109', '101-165',\n",
       "       '56-97', '79-106', '71-123', '90-124', '91-150', '141-225',\n",
       "       '145-225', '79-147', '122-146', '112-116', '110-163', '124-198',\n",
       "       '79-133', '69-116', '31-56', '95-119', '212-331', '66-112',\n",
       "       '128-201', '138-158', '80-132', '87-141', '92-155', '105-167'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 714,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cleaning_df['salary_estimate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cleaning_df['min_salary'] = features_cleaning_df['salary_estimate'].apply(lambda x: x.split('-')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cleaning_df['min_salary'] = features_cleaning_df['min_salary'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([137,  75,  79,  99,  90, 101,  56,  71,  91, 141, 145, 122, 112,\n",
       "       110, 124,  69,  31,  95, 212,  66, 128, 138,  80,  87,  92, 105])"
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cleaning_df['min_salary'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cleaning_df['max_salary'] = features_cleaning_df['salary_estimate'].apply(lambda x: x.split('-')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cleaning_df['max_salary'] = features_cleaning_df['max_salary'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([171, 131, 132, 109, 165,  97, 106, 123, 124, 150, 225, 147, 146,\n",
       "       116, 163, 198, 133,  56, 119, 331, 112, 201, 158, 141, 155, 167])"
      ]
     },
     "execution_count": 720,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cleaning_df['max_salary'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary_estimate</th>\n",
       "      <th>job_description</th>\n",
       "      <th>rating</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>headquarters</th>\n",
       "      <th>company_employees</th>\n",
       "      <th>type_of_ownership</th>\n",
       "      <th>industry</th>\n",
       "      <th>sector</th>\n",
       "      <th>revenue</th>\n",
       "      <th>job_location</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>max_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>137-171</td>\n",
       "      <td>Description\\n\\nThe Senior Data Scientist is re...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Healthfirst</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1001-5000</td>\n",
       "      <td>Nonprofit Organization</td>\n",
       "      <td>Insurance Carriers</td>\n",
       "      <td>Insurance</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>NY</td>\n",
       "      <td>137</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           job_title salary_estimate  \\\n",
       "0  Sr Data Scientist         137-171   \n",
       "\n",
       "                                     job_description  rating company_name  \\\n",
       "0  Description\\n\\nThe Senior Data Scientist is re...     3.1  Healthfirst   \n",
       "\n",
       "   location  headquarters company_employees       type_of_ownership  \\\n",
       "0  New York  New York, NY         1001-5000  Nonprofit Organization   \n",
       "\n",
       "             industry     sector                   revenue job_location  \\\n",
       "0  Insurance Carriers  Insurance  Unknown / Non-Applicable           NY   \n",
       "\n",
       "   min_salary  max_salary  \n",
       "0         137         171  "
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cleaning_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Average Salary New Feature\n",
    "\n",
    "In this step of data preprocessing, we created a new feature, average_salary, by calculating the average of the min_salary and max_salary for each job listing. This allows for a more straightforward representation of the salary range, enabling us to analyze and compare job salaries on a more consistent basis.\n",
    "\n",
    "The new average_salary feature was computed by summing the min_salary and max_salary for each entry and dividing the result by 2. We then converted the values to integers to ensure consistency and make the data ready for analysis or model training.\n",
    "\n",
    "This transformation simplifies the salary information, helping in tasks such as salary distribution analysis, comparisons, and even in prediction models for salary estimations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cleaning_df['average_salary'] = features_cleaning_df[['min_salary', 'max_salary']].apply(lambda x: (x['min_salary'] + x['max_salary']) / 2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cleaning_df['average_salary'] = features_cleaning_df['average_salary'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([154, 103, 105, 115,  99, 133,  76,  92,  97, 107, 120, 183, 185,\n",
       "       113, 134, 114, 136, 161, 106,  43, 271,  89, 164, 148, 123])"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cleaning_df['average_salary'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Same State Feature\n",
    "\n",
    "In this step, we created a new feature, same_state, to indicate whether the job's location is the same as the company's headquarters location. This binary feature helps identify if a job is located in the same state as the company's headquarters, which could be useful for understanding regional hiring trends or employee relocation preferences.\n",
    "\n",
    "The same_state feature was computed by comparing the location (job location) with the state portion of the headquarters (company headquarters). If the state in the location matches the state extracted from the headquarters, the same_state feature is assigned a value of 1; otherwise, it is assigned a value of 0.\n",
    "\n",
    "The result is a binary feature (1 or 0), where 1 indicates the job is in the same state as the company's headquarters, and 0 indicates it is not. This new feature adds additional value for analysis, particularly when exploring whether employees are generally hired locally or across state lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cleaning_df['same_state'] = features_cleaning_df[['location', 'headquarters']].apply(lambda x: 1 if  x['location'] == x['headquarters'].split(', ')[0] else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cleaning_df['same_state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "same_state\n",
       "0    402\n",
       "1    270\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cleaning_df['same_state'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Company Age New Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cleaning_df['company_age'] = df['Founded'].apply(lambda x: datetime.datetime.now().year - x if x != -1 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 32,  57,  44,  25,  27,  15,  29,  35,  42,  11,  13,   9,  60,\n",
       "        52,  39,  28,  10,  80,  37,   8,  14,  58, 165,  33,  22,  74,\n",
       "        20,   6, 100,  17,  26,  47,  59, 113,  67,  12, 176, 244,  99,\n",
       "        19,  31, 162,  30,  -1,  43,  51,  24,  40, 112,  54, 114,  16,\n",
       "        66,  18,  86,  23,  64,  62,  56,  79,  68,  72,  77, 175, 174,\n",
       "        21,  49, 107,  71,  78,  70,   7,  88, 108,  90,  96, 205,  73,\n",
       "        93, 131,  65, 237, 195,  41,  92, 145, 138,  55,  83,  45,  36,\n",
       "       117, 172, 150, 111, 127,  69,  48,  38, 129,  53,  76,  63],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cleaning_df['company_age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    32\n",
       "1    57\n",
       "2    44\n",
       "Name: company_age, dtype: int64"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cleaning_df['company_age'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary_estimate</th>\n",
       "      <th>job_description</th>\n",
       "      <th>rating</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>headquarters</th>\n",
       "      <th>company_employees</th>\n",
       "      <th>type_of_ownership</th>\n",
       "      <th>industry</th>\n",
       "      <th>sector</th>\n",
       "      <th>revenue</th>\n",
       "      <th>job_location</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>max_salary</th>\n",
       "      <th>average_salary</th>\n",
       "      <th>same_state</th>\n",
       "      <th>company_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>137-171</td>\n",
       "      <td>Description\\n\\nThe Senior Data Scientist is re...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Healthfirst</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1001-5000</td>\n",
       "      <td>Nonprofit Organization</td>\n",
       "      <td>Insurance Carriers</td>\n",
       "      <td>Insurance</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>NY</td>\n",
       "      <td>137</td>\n",
       "      <td>171</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>137-171</td>\n",
       "      <td>Secure our Nation, Ignite your Future\\n\\nJoin ...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>ManTech</td>\n",
       "      <td>Chantilly</td>\n",
       "      <td>Herndon, VA</td>\n",
       "      <td>5001-10000</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>$1 to $2 billion (USD)</td>\n",
       "      <td>VA</td>\n",
       "      <td>137</td>\n",
       "      <td>171</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>137-171</td>\n",
       "      <td>Overview\\n\\n\\nAnalysis Group is one of the lar...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Analysis Group</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>1001-5000</td>\n",
       "      <td>Private Practice / Firm</td>\n",
       "      <td>Consulting</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>$100 to $500 million (USD)</td>\n",
       "      <td>MA</td>\n",
       "      <td>137</td>\n",
       "      <td>171</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           job_title salary_estimate  \\\n",
       "0  Sr Data Scientist         137-171   \n",
       "1     Data Scientist         137-171   \n",
       "2     Data Scientist         137-171   \n",
       "\n",
       "                                     job_description  rating    company_name  \\\n",
       "0  Description\\n\\nThe Senior Data Scientist is re...     3.1     Healthfirst   \n",
       "1  Secure our Nation, Ignite your Future\\n\\nJoin ...     4.2         ManTech   \n",
       "2  Overview\\n\\n\\nAnalysis Group is one of the lar...     3.8  Analysis Group   \n",
       "\n",
       "    location  headquarters company_employees        type_of_ownership  \\\n",
       "0   New York  New York, NY         1001-5000   Nonprofit Organization   \n",
       "1  Chantilly   Herndon, VA        5001-10000         Company - Public   \n",
       "2     Boston    Boston, MA         1001-5000  Private Practice / Firm   \n",
       "\n",
       "                 industry             sector                     revenue  \\\n",
       "0      Insurance Carriers          Insurance    Unknown / Non-Applicable   \n",
       "1  Research & Development  Business Services      $1 to $2 billion (USD)   \n",
       "2              Consulting  Business Services  $100 to $500 million (USD)   \n",
       "\n",
       "  job_location  min_salary  max_salary  average_salary  same_state  \\\n",
       "0           NY         137         171             154           1   \n",
       "1           VA         137         171             154           0   \n",
       "2           MA         137         171             154           1   \n",
       "\n",
       "   company_age  \n",
       "0           32  \n",
       "1           57  \n",
       "2           44  "
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cleaning_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Python, Excel, Hadoop, Spark, AWS, Tableau, and Big Data New Features\n",
    "\n",
    "In this step, we created new features for specific skills mentioned in the job descriptions, such as Python, Excel, Hadoop, Spark, AWS, Tableau, and Big Data. These features were added to the dataset to provide a better understanding of the technical skills required for each job.\n",
    "\n",
    "Here’s how it works:\n",
    "\n",
    "1. For each skill in the list (python, excel, hadoop, spark, aws, tableau, big data), a new binary feature was created. The value for each new feature is determined by whether the corresponding skill appears in the job description text.\n",
    "\n",
    "2. The job description is converted to lowercase to ensure the skill is detected regardless of case sensitivity.\n",
    "\n",
    "3. If the skill is found in the job description, the corresponding feature is set to 1 (indicating that the skill is required for the job). If the skill is not found, the feature is set to 0.\n",
    "\n",
    "4. The feature name big data was renamed to big_data to follow a consistent naming convention, replacing the space with an underscore.\n",
    "\n",
    "These newly created features will allow us to quickly assess which jobs require specific technical skills, and they are especially helpful for machine learning models or further analysis of job trends in relation to specific skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['python', 'excel', 'hadoop', 'spark', 'aws', 'tableau', 'big data']\n",
    "\n",
    "for feature in features:\n",
    "    features_cleaning_df[feature] = features_cleaning_df['job_description'].apply(lambda x: 1 if feature in x.lower() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cleaning_df = features_cleaning_df.rename(columns={'big data': 'big_data'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary_estimate</th>\n",
       "      <th>job_description</th>\n",
       "      <th>rating</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>headquarters</th>\n",
       "      <th>company_employees</th>\n",
       "      <th>type_of_ownership</th>\n",
       "      <th>industry</th>\n",
       "      <th>...</th>\n",
       "      <th>average_salary</th>\n",
       "      <th>same_state</th>\n",
       "      <th>company_age</th>\n",
       "      <th>python</th>\n",
       "      <th>excel</th>\n",
       "      <th>hadoop</th>\n",
       "      <th>spark</th>\n",
       "      <th>aws</th>\n",
       "      <th>tableau</th>\n",
       "      <th>big_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>137-171</td>\n",
       "      <td>Description\\n\\nThe Senior Data Scientist is re...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Healthfirst</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1001-5000</td>\n",
       "      <td>Nonprofit Organization</td>\n",
       "      <td>Insurance Carriers</td>\n",
       "      <td>...</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           job_title salary_estimate  \\\n",
       "0  Sr Data Scientist         137-171   \n",
       "\n",
       "                                     job_description  rating company_name  \\\n",
       "0  Description\\n\\nThe Senior Data Scientist is re...     3.1  Healthfirst   \n",
       "\n",
       "   location  headquarters company_employees       type_of_ownership  \\\n",
       "0  New York  New York, NY         1001-5000  Nonprofit Organization   \n",
       "\n",
       "             industry  ... average_salary same_state company_age  python  \\\n",
       "0  Insurance Carriers  ...            154          1          32       0   \n",
       "\n",
       "   excel  hadoop  spark  aws  tableau  big_data  \n",
       "0      0       0      0    1        0         0  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 734,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cleaning_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job Simp Feature\n",
    "\n",
    "In this step, we create a new feature called job_simp, which simplifies job titles into broader categories. Here's a breakdown of how this works:\n",
    "\n",
    "1. Job Title Classification:\n",
    "* The function create_job_simp_feature checks for specific keywords (e.g., \"director\", \"manager\", \"data scientist\") in the job title. If one of these keywords is found in the job title, the function returns a simplified label corresponding to the role, such as 'Director', 'Manager', 'Data Scientist', etc. If none of the predefined keywords is found, it returns 'Na' (not available), indicating that the job title doesn't match any of the specified categories.\n",
    "\n",
    "2. Use of .apply():\n",
    "* The function is applied to the job_title column using .apply() to create the new job_simp feature.\n",
    "\n",
    "This categorization is helpful because it groups job titles into broad, simplified categories, making it easier to analyze job trends and focus on specific types of roles, rather than dealing with the variety of job titles that may exist in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sr Data Scientist', 'Data Scientist',\n",
       "       'Data Scientist / Machine Learning Expert',\n",
       "       'Staff Data Scientist - Analytics',\n",
       "       'Data Scientist - Statistics, Early Career', 'Data Modeler',\n",
       "       'Experienced Data Scientist', 'Data Scientist - Contract',\n",
       "       'Data Analyst II', 'Medical Lab Scientist',\n",
       "       'Data Scientist/Machine Learning', 'Human Factors Scientist',\n",
       "       'Business Intelligence Analyst I- Data Insights',\n",
       "       'Data Scientist - Risk', 'Data Scientist-Human Resources',\n",
       "       'Senior Research Statistician- Data Scientist', 'Data Engineer',\n",
       "       'Associate Data Scientist', 'Business Intelligence Analyst',\n",
       "       'Senior Analyst/Data Scientist', 'Data Analyst',\n",
       "       'Machine Learning Engineer', 'Data Analyst I',\n",
       "       'Scientist - Molecular Biology',\n",
       "       'Computational Scientist, Machine Learning',\n",
       "       'Senior Data Scientist', 'Jr. Data Engineer',\n",
       "       'E-Commerce Data Analyst', 'Data Analytics Engineer',\n",
       "       'Product Data Scientist - Ads Data Science',\n",
       "       'Data Scientist - Intermediate', 'Global Data Analyst',\n",
       "       'Data & Machine Learning Scientist',\n",
       "       'Data Scientist - Machine Learning', 'Data Engineer (Remote)',\n",
       "       'Data Scientist, Applied Machine Learning - Bay Area',\n",
       "       'Principal Data Scientist', 'Business Data Analyst',\n",
       "       'Purification Scientist', 'Data Engineer, Enterprise Analytics',\n",
       "       'Data Scientist 3 (718)', 'Real World Science, Data Scientist',\n",
       "       'Data Scientist - Image and Video Analytics',\n",
       "       'Data Science Manager, Payment Acceptance - USA',\n",
       "       'Data Scientist / Applied Mathematician',\n",
       "       'Patient Safety- Associate Data Scientist',\n",
       "       '(Sr.) Data Scientist -', 'Data Scientist, Kinship - NYC/Portland',\n",
       "       'Applied Technology Researcher / Data Scientist',\n",
       "       'Health Data Scientist - Biomedical/Biostats',\n",
       "       'Staff Data Scientist', 'Sr Data Engineer (Sr BI Developer)',\n",
       "       'Lead Data Scientist', 'RFP Data Analyst',\n",
       "       'Data Scientist (TS/SCI)', 'Software Engineer - Data Science',\n",
       "       'Data Analyst/Engineer', 'NGS Scientist', 'Senior Data Engineer',\n",
       "       'Sr. ML/Data Scientist - AI/NLP/Chatbot',\n",
       "       'Data Integration and Modeling Engineer',\n",
       "       'Tableau Data Engineer 20-0117', 'AI Data Scientist',\n",
       "       'Research Scientist Patient Preferences (Remote)',\n",
       "       'Scientist - Biomarker and Flow Cytometry', 'Analytics Manager',\n",
       "       'Staff Scientist- Upstream PD',\n",
       "       'Sr Scientist - Extractables & Leachables',\n",
       "       'ELISA RESEARCH SCIENTIST (CV-15)', 'Say Business Data Analyst',\n",
       "       'Geospatial Data Scientist', 'Computational Scientist',\n",
       "       'Senior Data Analyst', 'Sr Data Analyst',\n",
       "       'Machine Learning Scientist - Bay Area, CA',\n",
       "       'Senior Data Scientist - Algorithms',\n",
       "       'Senior Data & Machine Learning Scientist',\n",
       "       'Research Scientist - Patient-Centered Research (Remote)',\n",
       "       'Jr. Business Data Analyst (position added 6/12/2020)',\n",
       "       'Sr. Data Scientist II',\n",
       "       'Production Engineer - Statistics/Data Analysis',\n",
       "       'Statistical Scientist', 'Computational Behavioral Scientist',\n",
       "       'Principal Data Scientist - Machine Learning',\n",
       "       'Principal Machine Learning Scientist',\n",
       "       'Senior Data Scientist - R&D Oncology',\n",
       "       'Health Plan Data Analyst, Sr',\n",
       "       'Principal Scientist/Associate Director, Quality Control and Analytical Technologies',\n",
       "       'Analytics - Business Assurance Data Analyst',\n",
       "       'Senior Data Scientist – Image Analytics, Novartis AI Innovation Lab',\n",
       "       'Data Science Instructor', 'Senior Business Intelligence Analyst',\n",
       "       'In-Line Inspection Data Analyst',\n",
       "       'Data Scientist - TS/SCI FSP or CI Required',\n",
       "       'Data Scientist - TS/SCI Required',\n",
       "       'Data Science Software Engineer',\n",
       "       'ENGINEER - COMPUTER SCIENTIST - RESEARCH COMPUTER SCIENTIST - SIGNAL PROCESSING - SAN ANTONIO OR',\n",
       "       'AI Ops Data Scientist', 'Intelligence Data Analyst, Senior',\n",
       "       'Analytics Manager - Data Mart',\n",
       "       'Data Modeler (Analytical Systems)',\n",
       "       'Senior Machine Learning Scientist - Bay Area, CA',\n",
       "       'Report Writer-Data Analyst', 'Staff Data Scientist - Pricing',\n",
       "       'Equity Data Insights Analyst - Quantitative Analyst',\n",
       "       'Operations Data Analyst', 'Software Data Engineer',\n",
       "       'Real World Evidence (RWE) Scientist', 'Computer Scientist 1',\n",
       "       'Environmental Data Science', 'Staff BI and Data Engineer',\n",
       "       'Data Scientist - Statistics, Mid-Career',\n",
       "       'Director of Data Science',\n",
       "       'Data Engineer, Digital & Comp Pathology',\n",
       "       'Manager / Lead, Data Science & Analytics',\n",
       "       'Diversity and Inclusion Data Analyst',\n",
       "       'Data Scientist Machine Learning', 'Chief Scientist',\n",
       "       'Development Scientist, Voltaren',\n",
       "       'Principal Data & Analytics Platform Engineer',\n",
       "       'Machine Learning Engineer/Scientist',\n",
       "       'Data Analyst - Unilever Prestige', 'VP, Data Science',\n",
       "       'Data Engineer - Kafka', 'Decision Scientist',\n",
       "       'Data Science All Star Program - Data Engineer Track',\n",
       "       'Scientist - Machine Learning', 'Sr. Data Scientist',\n",
       "       'Applied AI Scientist / Engineer',\n",
       "       'Data Engineer (Analytics, SQL, Python, AWS)',\n",
       "       'Senior Data Analyst - Finance & Platform Analytics',\n",
       "       'Market Research Data Scientist',\n",
       "       'IT Partner Digital Health Technology and Data Science',\n",
       "       'Software Engineer (Data Scientist, C,C++,Linux,Unix) - SISW - MG',\n",
       "       'Senior Clinical Data Scientist Programmer',\n",
       "       'Computer Vision / Deep Learning Scientist',\n",
       "       'Data Solutions Engineer - Data Modeler',\n",
       "       'Data Scientist (TS/SCI w/ Poly)',\n",
       "       'Weapons and Sensors Engineer/Scientist',\n",
       "       'Applied Computer Scientist', 'Cloud Data Engineer (Azure)',\n",
       "       'Lead Certified Clinical Laboratory Scientist - Saturday - Tuesday, 8:00pm - 6:30am shift',\n",
       "       'Sr. Data Analyst',\n",
       "       'Senior Scientist - Toxicologist - Product Integrity (Stewardship)',\n",
       "       'Senior Machine Learning Engineer',\n",
       "       'Data Scientist- Industrial Discrete Sector Industry',\n",
       "       'Senior Principal Data Scientist (Python/R)',\n",
       "       'Data Scientist(s)/Machine Learning Engineer',\n",
       "       'Scientist / Group Lead, Cancer Biology',\n",
       "       'Manager, Field Application Scientist, Southeast',\n",
       "       'COMPUTER SCIENTIST - ENGINEER - RESEARCH COMPUTER SCIENTIST - SIGNAL PROCESSING',\n",
       "       'Machine Learning Scientist / Engineer', 'Data Science Analyst',\n",
       "       'COMPUTER SCIENTIST - ENGINEER - RESEARCH COMPUTER SCIENTIST - TRANSPORTATION TECHNOLOGY',\n",
       "       'Software Engineer - Machine Learning & Data Science (Applied Intelligence Services Team)',\n",
       "       'Clinical Data Analyst', 'Data Scientist Technical Specialist',\n",
       "       'Data Science Manager', 'Big Data Engineer', 'Data Architect',\n",
       "       'Aviation AI/ML Data Scientist', 'Machine Learning Engineer, Sr.',\n",
       "       'Information Systems Engineering Specialist (Engineering Scientist)',\n",
       "       'Scientist/Research Associate-Metabolic Engineering',\n",
       "       'Vice President, Biometrics and Clinical Data Management',\n",
       "       'Enterprise Data Analyst (Enterprise Portfolio Management Office)',\n",
       "       'Lead Data Scientist – Network Analysis and Control',\n",
       "       'Sr. Research Associate/ Scientist, NGS prep & Molecular Genomics',\n",
       "       'Developer III - Data Science',\n",
       "       'Hydrogen/Tritium Materials Scientist (Experienced)',\n",
       "       'Data Scientist/Data Analytics Practitioner',\n",
       "       'AI/ML - Machine Learning Scientist, Siri Understanding'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 743,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cleaning_df['job_title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_job_simp_feature(value):\n",
    "    if 'director' in value.lower():\n",
    "        return 'Director'\n",
    "    elif 'manager' in value.lower():\n",
    "        return 'Manager'\n",
    "    elif 'data scientist' in value.lower():\n",
    "        return 'Data Scientist'\n",
    "    elif 'analyst' in value.lower():\n",
    "        return 'Analyst'\n",
    "    elif 'data engineer' in value.lower():\n",
    "        return 'Data Engineer'\n",
    "    elif 'machine learning' in value.lower():\n",
    "        return 'Machine Learning'\n",
    "    else:\n",
    "        return 'Na'\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cleaning_df['job_simp'] = features_cleaning_df['job_title'].apply(create_job_simp_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_simp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>672 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             job_title        job_simp\n",
       "0    Sr Data Scientist  Data Scientist\n",
       "1       Data Scientist  Data Scientist\n",
       "2       Data Scientist  Data Scientist\n",
       "3       Data Scientist  Data Scientist\n",
       "4       Data Scientist  Data Scientist\n",
       "..                 ...             ...\n",
       "667     Data Scientist  Data Scientist\n",
       "668     Data Scientist  Data Scientist\n",
       "669     Data Scientist  Data Scientist\n",
       "670     Data Scientist  Data Scientist\n",
       "671     Data Scientist  Data Scientist\n",
       "\n",
       "[672 rows x 2 columns]"
      ]
     },
     "execution_count": 742,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cleaning_df[['job_title', 'job_simp']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seniority New Feature\n",
    "\n",
    "In this part of the project, I focused on creating a new feature called seniority to classify job titles based on their seniority level. The goal was to categorize roles as 'Junior', 'Senior', or 'Na' (not available) based on specific keywords in the job title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seniority_feature(value):\n",
    "    if 'jr' in value.lower():\n",
    "        return 'Junior'\n",
    "    if 'sr' in value.lower() or 'senior' in value.lower() or 'principal' in value.lower() or 'lead' in value.lower() or 'expert' in value.lower():\n",
    "        return 'Senior'\n",
    "    else:\n",
    "        return 'Na'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cleaning_df['seniority'] = features_cleaning_df['job_title'].apply(create_seniority_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary_estimate</th>\n",
       "      <th>job_description</th>\n",
       "      <th>rating</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>headquarters</th>\n",
       "      <th>company_employees</th>\n",
       "      <th>type_of_ownership</th>\n",
       "      <th>industry</th>\n",
       "      <th>...</th>\n",
       "      <th>company_age</th>\n",
       "      <th>python</th>\n",
       "      <th>excel</th>\n",
       "      <th>hadoop</th>\n",
       "      <th>spark</th>\n",
       "      <th>aws</th>\n",
       "      <th>tableau</th>\n",
       "      <th>big_data</th>\n",
       "      <th>job_simp</th>\n",
       "      <th>seniority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>137-171</td>\n",
       "      <td>Description\\n\\nThe Senior Data Scientist is re...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Healthfirst</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1001-5000</td>\n",
       "      <td>Nonprofit Organization</td>\n",
       "      <td>Insurance Carriers</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>137-171</td>\n",
       "      <td>Secure our Nation, Ignite your Future\\n\\nJoin ...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>ManTech</td>\n",
       "      <td>Chantilly</td>\n",
       "      <td>Herndon, VA</td>\n",
       "      <td>5001-10000</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>137-171</td>\n",
       "      <td>Overview\\n\\n\\nAnalysis Group is one of the lar...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Analysis Group</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>1001-5000</td>\n",
       "      <td>Private Practice / Firm</td>\n",
       "      <td>Consulting</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>137-171</td>\n",
       "      <td>JOB DESCRIPTION:\\n\\nDo you have a passion for ...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>INFICON</td>\n",
       "      <td>Newton</td>\n",
       "      <td>Bad Ragaz, Switzerland</td>\n",
       "      <td>501-1000</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Electrical &amp; Electronic Manufacturing</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>137-171</td>\n",
       "      <td>Data Scientist\\nAffinity Solutions / Marketing...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>Affinity Solutions</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>51-200</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Advertising &amp; Marketing</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Na</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           job_title salary_estimate  \\\n",
       "0  Sr Data Scientist         137-171   \n",
       "1     Data Scientist         137-171   \n",
       "2     Data Scientist         137-171   \n",
       "3     Data Scientist         137-171   \n",
       "4     Data Scientist         137-171   \n",
       "\n",
       "                                     job_description  rating  \\\n",
       "0  Description\\n\\nThe Senior Data Scientist is re...     3.1   \n",
       "1  Secure our Nation, Ignite your Future\\n\\nJoin ...     4.2   \n",
       "2  Overview\\n\\n\\nAnalysis Group is one of the lar...     3.8   \n",
       "3  JOB DESCRIPTION:\\n\\nDo you have a passion for ...     3.5   \n",
       "4  Data Scientist\\nAffinity Solutions / Marketing...     2.9   \n",
       "\n",
       "         company_name   location            headquarters company_employees  \\\n",
       "0         Healthfirst   New York            New York, NY         1001-5000   \n",
       "1             ManTech  Chantilly             Herndon, VA        5001-10000   \n",
       "2      Analysis Group     Boston              Boston, MA         1001-5000   \n",
       "3             INFICON     Newton  Bad Ragaz, Switzerland          501-1000   \n",
       "4  Affinity Solutions   New York            New York, NY            51-200   \n",
       "\n",
       "         type_of_ownership                               industry  ...  \\\n",
       "0   Nonprofit Organization                     Insurance Carriers  ...   \n",
       "1         Company - Public                 Research & Development  ...   \n",
       "2  Private Practice / Firm                             Consulting  ...   \n",
       "3         Company - Public  Electrical & Electronic Manufacturing  ...   \n",
       "4        Company - Private                Advertising & Marketing  ...   \n",
       "\n",
       "  company_age python excel  hadoop  spark  aws  tableau  big_data  \\\n",
       "0          32      0     0       0      0    1        0         0   \n",
       "1          57      0     0       1      0    0        0         1   \n",
       "2          44      1     1       0      0    1        0         0   \n",
       "3          25      1     1       0      0    1        0         0   \n",
       "4          27      1     1       0      0    0        0         0   \n",
       "\n",
       "         job_simp  seniority  \n",
       "0  Data Scientist     Senior  \n",
       "1  Data Scientist         Na  \n",
       "2  Data Scientist         Na  \n",
       "3  Data Scientist         Na  \n",
       "4  Data Scientist         Na  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 760,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cleaning_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = delete_outliers(features_cleaning_df, 2, [x for x in features_cleaning_df.columns if features_cleaning_df[x].dtype != 'object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 766,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cleaning_df = features_cleaning_df.drop(outliers, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cleaning_df.to_csv('finish.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [],
   "source": [
    "finished_df = features_cleaning_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary_estimate</th>\n",
       "      <th>job_description</th>\n",
       "      <th>rating</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>headquarters</th>\n",
       "      <th>company_employees</th>\n",
       "      <th>type_of_ownership</th>\n",
       "      <th>industry</th>\n",
       "      <th>...</th>\n",
       "      <th>company_age</th>\n",
       "      <th>python</th>\n",
       "      <th>excel</th>\n",
       "      <th>hadoop</th>\n",
       "      <th>spark</th>\n",
       "      <th>aws</th>\n",
       "      <th>tableau</th>\n",
       "      <th>big_data</th>\n",
       "      <th>job_simp</th>\n",
       "      <th>seniority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>137-171</td>\n",
       "      <td>Description\\n\\nThe Senior Data Scientist is re...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Healthfirst</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1001-5000</td>\n",
       "      <td>Nonprofit Organization</td>\n",
       "      <td>Insurance Carriers</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>137-171</td>\n",
       "      <td>Secure our Nation, Ignite your Future\\n\\nJoin ...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>ManTech</td>\n",
       "      <td>Chantilly</td>\n",
       "      <td>Herndon, VA</td>\n",
       "      <td>5001-10000</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>137-171</td>\n",
       "      <td>Overview\\n\\n\\nAnalysis Group is one of the lar...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Analysis Group</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>1001-5000</td>\n",
       "      <td>Private Practice / Firm</td>\n",
       "      <td>Consulting</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>137-171</td>\n",
       "      <td>JOB DESCRIPTION:\\n\\nDo you have a passion for ...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>INFICON</td>\n",
       "      <td>Newton</td>\n",
       "      <td>Bad Ragaz, Switzerland</td>\n",
       "      <td>501-1000</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Electrical &amp; Electronic Manufacturing</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>137-171</td>\n",
       "      <td>Data Scientist\\nAffinity Solutions / Marketing...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>Affinity Solutions</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>51-200</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Advertising &amp; Marketing</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>137-171</td>\n",
       "      <td>About Us:\\n\\nHeadquartered in beautiful Santa ...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>HG Insights</td>\n",
       "      <td>Santa Barbara</td>\n",
       "      <td>Santa Barbara, CA</td>\n",
       "      <td>51-200</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Computer Hardware &amp; Software</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist / Machine Learning Expert</td>\n",
       "      <td>137-171</td>\n",
       "      <td>Posting Title\\nData Scientist / Machine Learni...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Novartis</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>Basel, Switzerland</td>\n",
       "      <td>10000+</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Biotech &amp; Pharmaceuticals</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>137-171</td>\n",
       "      <td>Introduction\\n\\nHave you always wanted to run ...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>iRobot</td>\n",
       "      <td>Bedford</td>\n",
       "      <td>Bedford, MA</td>\n",
       "      <td>1001-5000</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Consumer Electronics &amp; Appliances Stores</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Staff Data Scientist - Analytics</td>\n",
       "      <td>137-171</td>\n",
       "      <td>Intuit is seeking a Staff Data Scientist to co...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Intuit - Data</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>Mountain View, CA</td>\n",
       "      <td>5001-10000</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Computer Hardware &amp; Software</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>137-171</td>\n",
       "      <td>Ready to write the best chapter of your career...</td>\n",
       "      <td>3.6</td>\n",
       "      <td>XSELL Technologies</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>51-200</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Enterprise Software &amp; Network Solutions</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Na</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  job_title salary_estimate  \\\n",
       "0                         Sr Data Scientist         137-171   \n",
       "1                            Data Scientist         137-171   \n",
       "2                            Data Scientist         137-171   \n",
       "3                            Data Scientist         137-171   \n",
       "4                            Data Scientist         137-171   \n",
       "5                            Data Scientist         137-171   \n",
       "6  Data Scientist / Machine Learning Expert         137-171   \n",
       "7                            Data Scientist         137-171   \n",
       "8          Staff Data Scientist - Analytics         137-171   \n",
       "9                            Data Scientist         137-171   \n",
       "\n",
       "                                     job_description  rating  \\\n",
       "0  Description\\n\\nThe Senior Data Scientist is re...     3.1   \n",
       "1  Secure our Nation, Ignite your Future\\n\\nJoin ...     4.2   \n",
       "2  Overview\\n\\n\\nAnalysis Group is one of the lar...     3.8   \n",
       "3  JOB DESCRIPTION:\\n\\nDo you have a passion for ...     3.5   \n",
       "4  Data Scientist\\nAffinity Solutions / Marketing...     2.9   \n",
       "5  About Us:\\n\\nHeadquartered in beautiful Santa ...     4.2   \n",
       "6  Posting Title\\nData Scientist / Machine Learni...     3.9   \n",
       "7  Introduction\\n\\nHave you always wanted to run ...     3.5   \n",
       "8  Intuit is seeking a Staff Data Scientist to co...     4.4   \n",
       "9  Ready to write the best chapter of your career...     3.6   \n",
       "\n",
       "         company_name       location            headquarters  \\\n",
       "0         Healthfirst       New York            New York, NY   \n",
       "1             ManTech      Chantilly             Herndon, VA   \n",
       "2      Analysis Group         Boston              Boston, MA   \n",
       "3             INFICON         Newton  Bad Ragaz, Switzerland   \n",
       "4  Affinity Solutions       New York            New York, NY   \n",
       "5         HG Insights  Santa Barbara       Santa Barbara, CA   \n",
       "6            Novartis      Cambridge      Basel, Switzerland   \n",
       "7              iRobot        Bedford             Bedford, MA   \n",
       "8       Intuit - Data      San Diego       Mountain View, CA   \n",
       "9  XSELL Technologies        Chicago             Chicago, IL   \n",
       "\n",
       "  company_employees        type_of_ownership  \\\n",
       "0         1001-5000   Nonprofit Organization   \n",
       "1        5001-10000         Company - Public   \n",
       "2         1001-5000  Private Practice / Firm   \n",
       "3          501-1000         Company - Public   \n",
       "4            51-200        Company - Private   \n",
       "5            51-200        Company - Private   \n",
       "6            10000+         Company - Public   \n",
       "7         1001-5000         Company - Public   \n",
       "8        5001-10000         Company - Public   \n",
       "9            51-200        Company - Private   \n",
       "\n",
       "                                   industry  ... company_age python excel  \\\n",
       "0                        Insurance Carriers  ...          32      0     0   \n",
       "1                    Research & Development  ...          57      0     0   \n",
       "2                                Consulting  ...          44      1     1   \n",
       "3     Electrical & Electronic Manufacturing  ...          25      1     1   \n",
       "4                   Advertising & Marketing  ...          27      1     1   \n",
       "5              Computer Hardware & Software  ...          15      1     1   \n",
       "6                 Biotech & Pharmaceuticals  ...          29      1     0   \n",
       "7  Consumer Electronics & Appliances Stores  ...          35      1     0   \n",
       "8              Computer Hardware & Software  ...          42      0     0   \n",
       "9   Enterprise Software & Network Solutions  ...          11      1     0   \n",
       "\n",
       "   hadoop  spark  aws  tableau  big_data        job_simp  seniority  \n",
       "0       0      0    1        0         0  Data Scientist     Senior  \n",
       "1       1      0    0        0         1  Data Scientist         Na  \n",
       "2       0      0    1        0         0  Data Scientist         Na  \n",
       "3       0      0    1        0         0  Data Scientist         Na  \n",
       "4       0      0    0        0         0  Data Scientist         Na  \n",
       "5       1      1    0        0         0  Data Scientist         Na  \n",
       "6       0      0    0        0         0  Data Scientist     Senior  \n",
       "7       0      0    0        0         0  Data Scientist         Na  \n",
       "8       0      0    0        0         0  Data Scientist         Na  \n",
       "9       0      0    0        0         0  Data Scientist         Na  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "execution_count": 772,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finished_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
